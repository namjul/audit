import meow from 'meow';
import _defineProperty from '@babel/runtime/helpers/esm/defineProperty';
import * as path from 'path';
import path__default from 'path';
import enquirer from 'enquirer';
import pLimit from 'p-limit';
import DataLoader from 'dataloader';
import chalk from 'chalk';
import fastGlob from 'fast-glob';
import * as fs from 'fs-extra';
import fs__default from 'fs-extra';
import _objectSpread from '@babel/runtime/helpers/esm/objectSpread2';
import detectIndent from 'detect-indent';
import parseJson from 'parse-json';
import fsPromises from 'fs/promises';
import util from 'util';
import normalizePath from 'normalize-path';
import parseGlob from 'parse-glob';
import { z } from 'zod';
import packlist from 'npm-packlist';
import equal from 'fast-deep-equal';
import resolveFrom from 'resolve-from';
import { rollup, watch } from 'rollup';
import resolve from '@rollup/plugin-node-resolve';
import alias from '@rollup/plugin-alias';
import cjs from '@rollup/plugin-commonjs';
import replace from '@rollup/plugin-replace';
import builtInModules from 'builtin-modules';
import { EOL } from 'os';
import MagicString from 'magic-string';
import json from '@rollup/plugin-json';
import Worker from 'jest-worker';
import { isCI } from 'ci-info';
import QuickLRU from 'quick-lru';
import semver from 'semver';
import { codeFrameColumns } from '@babel/code-frame';
import { walk } from 'estree-walker';
import isReference from 'is-reference';
import ms from 'ms';

let limit = pLimit(1); // there might be a simpler solution to this than using dataloader but it works so Â¯\_(ãƒ„)_/Â¯

let prefix = `ðŸŽ ${chalk.green("?")}`;
function createPromptConfirmLoader(message) {
  let loader = new DataLoader(pkgs => limit(() => (async () => {
    if (pkgs.length === 1) {
      // @ts-ignore
      let {
        confirm
      } = await enquirer.prompt([{
        // @ts-ignore
        type: "confirm",
        name: "confirm",
        message,
        // @ts-ignore
        prefix: prefix + " " + pkgs[0].name,
        initial: true
      }]);
      return [confirm];
    } // @ts-ignore


    let {
      answers
    } = await enquirer.prompt([{
      type: "multiselect",
      name: "answers",
      message,
      choices: pkgs.map(pkg => ({
        name: pkg.name,
        initial: true
      })),
      // @ts-ignore
      prefix
    }]);
    return pkgs.map(pkg => {
      return answers.includes(pkg.name);
    });
  })()));
  return pkg => loader.load(pkg);
}
let doPromptInput = async (message, pkg, defaultAnswer) => {
  // @ts-ignore
  let {
    input
  } = await enquirer.prompt([{
    // @ts-ignore
    type: "input",
    name: "input",
    message,
    // @ts-ignore
    prefix: prefix + " " + pkg.name,
    initial: defaultAnswer
  }]);
  return input;
};
let promptInput = (message, pkg, defaultAnswer) => limit(() => doPromptInput(message, pkg, defaultAnswer));

class Item {
  constructor(filePath, contents, jsonDataByPath) {
    _defineProperty(this, "path", void 0);

    _defineProperty(this, "indent", void 0);

    _defineProperty(this, "directory", void 0);

    _defineProperty(this, "_jsonDataByPath", void 0);

    this.indent = detectIndent(contents).indent || "  ";
    this.path = filePath;
    this.directory = path__default.dirname(filePath);
    this._jsonDataByPath = jsonDataByPath;

    if (!jsonDataByPath.has(this.path)) {
      const json = parseJson(contents, filePath);
      jsonDataByPath.set(this.path, {
        value: json,
        stringifiedSaved: JSON.stringify(json)
      });

      if (!this.json.preconstruct) {
        this.json.preconstruct = {};
      }
    }
  }

  get json() {
    return this._jsonDataByPath.get(this.path).value;
  }

  set json(value) {
    this._jsonDataByPath.set(this.path, {
      value,
      stringifiedSaved: this._jsonDataByPath.get(this.path).stringifiedSaved
    });
  }

  async save() {
    const json = _objectSpread({}, this.json);

    if (json.preconstruct && json.preconstruct !== null && typeof json.preconstruct === "object" && !Object.keys(json.preconstruct).length) {
      delete json.preconstruct;
    }

    let stringified = JSON.stringify(json);

    if (stringified !== this._jsonDataByPath.get(this.path).stringifiedSaved) {
      await fs.writeFile(this.path, JSON.stringify(json, null, this.indent) + "\n");
      return true;
    }

    return false;
  }

}

function format(message, messageType, scope) {
  let prefix = {
    error: " " + chalk.red("error"),
    success: " " + chalk.green("success"),
    info: " " + chalk.cyan("info"),
    none: ""
  }[messageType];
  let fullPrefix = "ðŸŽ" + prefix + (scope ? " " + chalk.cyan(scope) : "");
  return String(message).split("\n").map(line => {
    if (!line.trim()) {
      return fullPrefix;
    }

    return `${fullPrefix} ${line}`;
  }).join("\n");
}
function error(message, scope) {
  console.error(format(message, "error", scope));
}
function success(message, scope) {
  console.log(format(message, "success", scope));
}
function info(message, scope) {
  console.log(format(message, "info", scope));
}
function log(message) {
  console.log(format(message, "none"));
}

class FatalError extends Error {
  constructor(message, scope) {
    super(message);

    _defineProperty(this, "scope", void 0);

    this.scope = scope;
  }

}
class BatchError extends Error {
  constructor(errors) {
    super(errors.map(x => {
      return format(x.message, "none", x.scope);
    }).join("\n"));

    _defineProperty(this, "errors", void 0);

    this.errors = errors;
  }

}
class ScopelessError extends Error {}
class UnexpectedBuildError extends FatalError {
  constructor(error, pkgName) {
    super(`${util.format("", error).trim()}`, pkgName);
  }

}
class FixableError extends FatalError {}

class Entrypoint extends Item {
  constructor(filePath, contents, pkg, source) {
    super(filePath, contents, pkg._jsonDataByPath);

    _defineProperty(this, "package", void 0);

    _defineProperty(this, "source", void 0);

    _defineProperty(this, "afterPackageName", void 0);

    this.package = pkg;
    this.source = source;
    this.afterPackageName = pkg.directory === this.directory ? "" : "/" + normalizePath(path__default.dirname(path__default.relative(pkg.directory, filePath)));
  }

  get hasModuleField() {
    return this.json.module !== undefined;
  }

  get name() {
    return this.package.name + this.afterPackageName;
  }

}

const EXTENSIONS = [".js", ".jsx", ".ts", ".tsx"];
const PKG_JSON_CONFIG_FIELD = "preconstruct";

let errors$1 = {
  noSource: source => `no source file was provided, please create a file at ${source} or specify a custom source file with the ${PKG_JSON_CONFIG_FIELD} source option`,
  deniedWriteMainField: "changing the main field is required to build",
  invalidField: (field, found, expected) => `${field} field ${found === undefined ? chalk.red("was not found") : `is invalid, found \`${chalk.red(JSON.stringify(found))}\``}, expected \`${chalk.green(JSON.stringify(expected))}\``,
  umdNameNotSpecified: `the umd:main field is specified but a umdName option is not specified. please add it to the ${PKG_JSON_CONFIG_FIELD} field in your package.json`,
  noEntrypointPkgJson: "There is a missing package.json for an entrypoint",
  noEntrypoints: "packages must have at least one entrypoint, this package has no entrypoints",
  fieldMustExistInAllEntrypointsIfExistsDeclinedFixDuringInit: field => `all entrypoints in a package must have the same fields and one entrypoint in this package has a ${field} field but you've declined the fix`,
  missingBrowserConditionWithFieldPresent: `the exports field is configured and the browser field exists in this package but it is not specified in the preconstruct.exports.envConditions field`,
  missingBrowserFieldWithConditionPresent: `the exports field is configured and the browser condition is set in preconstruct.exports.envConditions but the field is not present at the top-level`,
  noModuleFieldWithExportsField: `when using the exports field, the module field must also be specified`
};
let confirms = {
  writeMainField: createPromptConfirmLoader("preconstruct is going to change the main field in your package.json, are you okay with that?"),
  writeModuleField: createPromptConfirmLoader("would you like to generate module builds? this will write to the module field in your package.json"),
  fixModuleField: createPromptConfirmLoader("would you like to fix the module field?"),
  fixUmdBuild: createPromptConfirmLoader("would you like to fix the umd field?"),
  fixBrowserField: createPromptConfirmLoader("would you like to fix the browser build?"),
  createEntrypointPkgJson: createPromptConfirmLoader("A package.json file does not exist for this entrypoint, would you like to create one automatically?"),
  createEntrypoint: createPromptConfirmLoader("This glob does not match anything, would you like to create an entrypoint for it?"),
  deleteEntrypointPkgJson: createPromptConfirmLoader("The package.json file this entrypoint is unnecessary with type: module, would you like to delete it?")
};
let inputs = {
  getUmdName: "what should the name used for UMD bundles be?",
  getSource: "what should the source file for this entrypoint be?"
};
let infos = {
  validField: field => `${field} field is valid`,
  validEntrypoint: "a valid entry point exists.",
  validPackageEntrypoints: "package entrypoints are valid"
};
let successes = {
  validProject: "project is valid!",
  startedWatching: "started watching!"
};

async function getUselessGlobsThatArentReallyGlobsForNewEntrypoints(globs, files, cwd) {
  let filesSet = new Set(files.map(x => normalizePath(x)));
  return (await Promise.all(globs.map(async glob => {
    let parsedGlobResult = parseGlob(glob);

    if (!parsedGlobResult.is.glob) {
      let filename = normalizePath(path__default.resolve(cwd, "src", glob));
      if (filesSet.has(filename)) return;

      try {
        await fs.stat(filename);
      } catch (err) {
        if (err.code === "ENOENT") {
          return {
            filename,
            glob,
            exists: false
          };
        }

        throw err;
      }

      return {
        filename,
        glob,
        exists: true
      };
    }
  }))).filter(x => !!x);
}

// for `imports` when it's going to be compiled away in what people import
// (if people think they want it, they're almost always wrong because it doesn't do what they think it does)

const conditionsSchema = z.lazy(() => z.union([z.string(), z.null(), z.record(conditionsSchema)]));
const importsSchema = z.record(z.string().startsWith("#"), conditionsSchema).default({});

function getAllConditions(imports) {
  const allConditions = new Set();

  for (const conditions of Object.values(imports)) {
    findConditions(conditions, allConditions);
  }

  return [...allConditions].sort();
}

function parseImportsField(input) {
  const parsed = importsSchema.parse(input);
  const sortedConditions = getAllConditions(parsed);
  const resolvedToConditions = new Map();

  for (const combination of getCombinations(sortedConditions)) {
    const resolved = Object.entries(parsed).map(([specifier, conditions]) => {
      const resolved = resolveConditions(conditions, combination);

      if (resolved === null) {
        throw new Error(`imports.${specifier} is missing a default`);
      }

      return resolved;
    });
    const resolvedString = JSON.stringify(resolved);

    if (!resolvedToConditions.has(resolvedString)) {
      resolvedToConditions.set(resolvedString, [combination]);
      continue;
    }

    resolvedToConditions.get(resolvedString).push(combination);
  }

  const buildToCombinations = new Map([...resolvedToConditions.values()].map(combinations => {
    let shortestCombination = combinations[0];

    for (const combination of combinations) {
      if (combination.length < shortestCombination.length) {
        shortestCombination = combination;
      }
    }

    return [shortestCombination, combinations];
  }));
  return buildToCombinations;
}
function createExportsField(buildToCombinations, toLeaf) {
  const combinationsToBuild = new Map();
  const conditionsToBuildCount = new Map();
  const conditionsToInBuildCount = new Map();

  for (const [build, combinations] of buildToCombinations) {
    for (const condition of new Set(combinations.flat())) {
      var _conditionsToInBuildC;

      conditionsToInBuildCount.set(condition, ((_conditionsToInBuildC = conditionsToInBuildCount.get(condition)) !== null && _conditionsToInBuildC !== void 0 ? _conditionsToInBuildC : 0) + 1);
    }

    for (const condition of new Set(build)) {
      var _conditionsToBuildCou;

      conditionsToBuildCount.set(condition, ((_conditionsToBuildCou = conditionsToBuildCount.get(condition)) !== null && _conditionsToBuildCou !== void 0 ? _conditionsToBuildCou : 0) + 1);
    }

    const leaf = toLeaf(build);

    for (const combination of combinations) {
      combinationsToBuild.set(JSON.stringify(combination), leaf);
    }
  } // i'm not totally sure if this is right or the best way to do this
  // but it seems to work i think


  const conditionsInExportsFieldOrder = [...conditionsToInBuildCount.keys()].sort().sort((a, b) => {
    var _conditionsToBuildCou2, _conditionsToInBuildC2, _conditionsToBuildCou3, _conditionsToInBuildC3, _conditionsToInBuildC4, _conditionsToInBuildC5;

    const aBuildVsInDiff = ((_conditionsToBuildCou2 = conditionsToBuildCount.get(a)) !== null && _conditionsToBuildCou2 !== void 0 ? _conditionsToBuildCou2 : 0) - ((_conditionsToInBuildC2 = conditionsToInBuildCount.get(a)) !== null && _conditionsToInBuildC2 !== void 0 ? _conditionsToInBuildC2 : 0);
    const bBuildVsInDiff = ((_conditionsToBuildCou3 = conditionsToBuildCount.get(b)) !== null && _conditionsToBuildCou3 !== void 0 ? _conditionsToBuildCou3 : 0) - ((_conditionsToInBuildC3 = conditionsToInBuildCount.get(b)) !== null && _conditionsToInBuildC3 !== void 0 ? _conditionsToInBuildC3 : 0);

    if (aBuildVsInDiff === 0 && bBuildVsInDiff === 0) {
      var _conditionsToBuildCou4, _conditionsToBuildCou5;

      return ((_conditionsToBuildCou4 = conditionsToBuildCount.get(b)) !== null && _conditionsToBuildCou4 !== void 0 ? _conditionsToBuildCou4 : 0) - ((_conditionsToBuildCou5 = conditionsToBuildCount.get(a)) !== null && _conditionsToBuildCou5 !== void 0 ? _conditionsToBuildCou5 : 0);
    }

    return ((_conditionsToInBuildC4 = conditionsToInBuildCount.get(a)) !== null && _conditionsToInBuildC4 !== void 0 ? _conditionsToInBuildC4 : 0) - ((_conditionsToInBuildC5 = conditionsToInBuildCount.get(b)) !== null && _conditionsToInBuildC5 !== void 0 ? _conditionsToInBuildC5 : 0);
  });
  return _createExportsField(conditionsInExportsFieldOrder, [], combinationsToBuild);
}

function _createExportsField(combinationsLeft, parentCombinations, combinationToBuild) {
  if (combinationsLeft.length === 0) {
    const build = combinationToBuild.get(JSON.stringify([...parentCombinations].sort()));

    if (!build) {
      throw new Error("missing build");
    }

    return build;
  }

  const [currentCondition, ...rest] = combinationsLeft;

  const withCurrent = _createExportsField(rest, [...parentCombinations, currentCondition], combinationToBuild);

  const withoutCurrent = _createExportsField(rest, parentCombinations, combinationToBuild);

  if (withCurrent === withoutCurrent) {
    return withCurrent;
  }

  if (typeof withoutCurrent !== "object" || Array.isArray(withoutCurrent) || withoutCurrent === null) {
    return {
      [currentCondition]: withCurrent,
      default: withoutCurrent
    };
  }

  return _objectSpread({
    [currentCondition]: withCurrent
  }, withoutCurrent);
}

function resolveConditions(written, combination) {
  if (typeof written === "string" || written === null) {
    return written;
  }

  for (const [condition, value] of Object.entries(written)) {
    if (condition === "default" || combination.includes(condition)) {
      const resolved = resolveConditions(value, combination);
      if (resolved !== undefined) return resolved;
    }
  }

  return undefined;
}

const bannedConditions = new Set(["import", "require", "module", "types"]);

function findConditions(specified, conditions) {
  if (typeof specified === "string" || specified === null) {
    return;
  }

  for (const [condition, value] of Object.entries(specified)) {
    if (bannedConditions.has(condition) || condition.startsWith("types@")) {
      throw new Error(`condition ${condition} is not allowed in the imports field with preconstruct`);
    }

    if (condition === "default") {
      findConditions(value, conditions);
      continue;
    }

    conditions.add(condition);
    findConditions(value, conditions);
  }
}

function getCombinations(arr) {
  const result = [[]];

  for (const item of arr) {
    const currentLength = result.length;

    for (let i = 0; i < currentLength; i++) {
      const currentCombination = result[i];
      result.push([...currentCombination, item]);
    }
  }

  return result;
}

let fields = ["version", "description", "main", "module", "umd:main", "browser", "exports"];
function setFieldInOrder(obj, field, value) {
  if (field in obj) {
    let newObj = _objectSpread({}, obj);

    newObj[field] = value;
    return newObj;
  }

  let fieldIndex = fields.indexOf(field);
  let idealField = fields.slice(0, fieldIndex).reverse().find(key => {
    return key in obj;
  });

  if (idealField === undefined) {
    return _objectSpread(_objectSpread({}, obj), {}, {
      [field]: value
    });
  }

  let newObj = {};

  for (let key in obj) {
    newObj[key] = obj[key];

    if (key === idealField) {
      newObj[field] = value;
    }
  }

  return newObj;
}
function getEntrypointName(pkg, entrypointDir) {
  return normalizePath(path.join(pkg.name, path.relative(pkg.directory, path.resolve(pkg.directory, entrypointDir))));
}
function getBaseDistName(entrypoint) {
  const strategy = entrypoint.package.distFilenameStrategy;

  if (strategy === "full") {
    return entrypoint.name.replace("@", "").replace(/\//g, "-");
  }

  return entrypoint.package.name.replace(/.*\//, "");
}
function exportsField(pkg) {
  const exportsFieldConfig = pkg.exportsFieldConfig();

  if (!exportsFieldConfig) {
    return;
  }

  let output = {};

  if (exportsFieldConfig.conditions.kind === "legacy") {
    output = exportsFieldForLegacyConditions(pkg, exportsFieldConfig.conditions.envs, exportsFieldConfig.importConditionDefaultExport);
  } else {
    const isTypeModule = pkg.isTypeModule();

    for (const entrypoint of pkg.entrypoints) {
      if (isTypeModule) {
        const groups = [...exportsFieldConfig.conditions.groups];
        const hasNoConditions = groups.length === 1 && groups[0][0].length === 0 && groups[0][1].length === 1 && groups[0][1][0].length === 0;
        const exportsField = createExportsField(exportsFieldConfig.conditions.groups, conditions => ({
          default: getExportsFieldOutputPathForConditionsWithTypeModule(entrypoint, conditions)
        }));
        const key = "." + entrypoint.afterPackageName;

        if (hasNoConditions && Object.keys(exportsField).length === 1 && exportsField.default) {
          output[key] = exportsField.default;
          continue;
        }

        const exports = createExportsField(exportsFieldConfig.conditions.groups, conditions => getExportsFieldOutputPathForConditionsWithTypeModule(entrypoint, conditions));
        output[key] = _objectSpread({
          // yes, i'm very intentionally pointing at the .js/.mjs rather than the .d.ts/.d.mts
          // TODO: this should probably only be here if you're using ts
          // or maybe we just generate more .d.ts files in the dist rather than having a types condition
          types: getExportsFieldOutputPathForConditionsWithTypeModule(entrypoint, [])
        }, typeof exports === "string" ? {
          default: exports
        } : exports);
        continue;
      }

      output["." + entrypoint.afterPackageName] = _objectSpread({
        // yes, i'm very intentionally pointing at the .js/.mjs rather than the .d.ts/.d.mts
        // TODO: this should probably only be here if you're using ts
        // or maybe we just generate more .d.ts files in the dist rather than having a types condition
        types: exportsFieldConfig.importConditionDefaultExport === "default" ? {
          import: getExportsFieldOutputPathForConditions(entrypoint, ["import"]),
          default: getExportsFieldOutputPathForConditions(entrypoint, [])
        } : getExportsFieldOutputPathForConditions(entrypoint, [])
      }, createExportsField(exportsFieldConfig.conditions.groups, conditions => _objectSpread(_objectSpread({
        module: getExportsFieldOutputPathForConditions(entrypoint, conditions.concat("module"))
      }, exportsFieldConfig.importConditionDefaultExport === "default" && {
        import: getExportsFieldOutputPathForConditions(entrypoint, conditions.concat("import"))
      }), {}, {
        default: getExportsFieldOutputPathForConditions(entrypoint, conditions)
      })));
    }
  }

  return _objectSpread(_objectSpread({}, output), {}, {
    "./package.json": "./package.json"
  }, exportsFieldConfig.extra);
}

function exportsFieldForLegacyConditions(pkg, envs, importConditionDefaultExport) {
  let output = {};

  for (const entrypoint of pkg.entrypoints) {
    const esmBuild = getExportsFieldOutputPath(entrypoint, "esm");

    const exportConditions = _objectSpread(_objectSpread({
      module: envs.size ? _objectSpread(_objectSpread(_objectSpread({}, envs.has("worker") && {
        worker: getExportsFieldOutputPath(entrypoint, "worker")
      }), envs.has("browser") && {
        browser: getExportsFieldOutputPath(entrypoint, "browser-esm")
      }), {}, {
        default: esmBuild
      }) : esmBuild
    }, importConditionDefaultExport === "default" && {
      import: getExportsImportUnwrappingDefaultOutputPath(entrypoint)
    }), {}, {
      default: getExportsFieldOutputPath(entrypoint, "cjs")
    });

    output["." + entrypoint.afterPackageName] = exportConditions;
  }

  return output;
}

const buildTargetToExtensionPrefix = {
  cjs: "cjs",
  esm: "esm",
  "browser-cjs": "browser.cjs",
  "browser-esm": "browser.esm",
  worker: "worker.esm",
  umd: "umd.min"
};
function getDistExtension(target) {
  return `${buildTargetToExtensionPrefix[target]}.js`;
}
function getDistExtensionForConditions(conditions) {
  const forJoining = [];
  let ext = "cjs.js";

  for (const condition of conditions) {
    if (condition === "module") {
      if (ext !== "cjs.js") {
        throw new Error(`unexpected module and import conditions together`);
      }

      ext = "esm.js";
      continue;
    }

    if (condition === "import") {
      if (ext !== "cjs.js") {
        throw new Error(`unexpected module and import conditions together`);
      }

      ext = "cjs.mjs";
      continue;
    }

    forJoining.push(condition);
  }

  forJoining.push(ext);
  return forJoining.join(".");
}
function getDistFilenameForConditions(entrypoint, conditions) {
  return `dist/${getBaseDistName(entrypoint)}.${getDistExtensionForConditions(conditions)}`;
}
function getBaseDistFilename(entrypoint, target) {
  return `${getBaseDistName(entrypoint)}.${getDistExtension(target)}`;
}

function getDistFilename(entrypoint, target) {
  if (entrypoint.package.project.experimentalFlags.distInRoot) {
    if (entrypoint.package.name === entrypoint.name) {
      return `dist/${getBaseDistFilename(entrypoint, target)}`;
    }

    return "../".repeat(entrypoint.name.slice(entrypoint.package.name.length + 1).split("/").length) + `dist/${getBaseDistFilename(entrypoint, target)}`;
  }

  return `dist/${getBaseDistFilename(entrypoint, target)}`;
}

function getExportsFieldEntrypointOutputPrefix(entrypoint) {
  if (entrypoint.package.project.experimentalFlags.distInRoot) return "./";
  return `.${entrypoint.afterPackageName}/`;
}

function getExportsFieldOutputPath(entrypoint, target) {
  return getExportsFieldEntrypointOutputPrefix(entrypoint) + getDistFilename(entrypoint, target);
}
function getExportsFieldOutputPathForConditions(entrypoint, conditions) {
  return getExportsFieldEntrypointOutputPrefix(entrypoint) + getDistFilenameForConditions(entrypoint, conditions);
}
function getExportsFieldOutputPathForConditionsWithTypeModule(entrypoint, conditions) {
  return getExportsFieldEntrypointOutputPrefix(entrypoint) + getDistFilenameForConditionsWithTypeModule(entrypoint, conditions);
}
function getDistFilenameForConditionsWithTypeModule(entrypoint, conditions) {
  return `dist/${getBaseDistName(entrypoint)}.${getDistExtensionForConditionsWithTypeModule(conditions)}`;
}
function getDistExtensionForConditionsWithTypeModule(conditions) {
  if (conditions.length === 0) return "js";
  return `${conditions.join(".")}.js`;
}
function getExportsImportUnwrappingDefaultOutputPath(entrypoint) {
  return getExportsFieldOutputPath(entrypoint, "cjs").replace(/\.js$/, ".mjs");
}
const validFieldsForEntrypoint = {
  main(entrypoint) {
    return getDistFilename(entrypoint, "cjs");
  },

  module(entrypoint) {
    return getDistFilename(entrypoint, "esm");
  },

  "umd:main"(entrypoint) {
    return getDistFilename(entrypoint, "umd");
  },

  browser(entrypoint) {
    const moduleBuild = {
      [`./${getDistFilename(entrypoint, "esm")}`]: `./${getDistFilename(entrypoint, "browser-esm")}`
    };

    if (entrypoint.package.exportsFieldConfig()) {
      return moduleBuild;
    }

    return _objectSpread({
      [`./${getDistFilename(entrypoint, "cjs")}`]: `./${getDistFilename(entrypoint, "browser-cjs")}`
    }, entrypoint.hasModuleField && moduleBuild);
  }

};
function flowTemplate(hasDefaultExport, relativePath) {
  const escapedPath = JSON.stringify(relativePath);
  return `// @flow
export * from ${escapedPath};${hasDefaultExport ? `\nexport { default } from ${escapedPath};` : ""}\n`;
}

function esmReexportTemplate(hasDefaultExport, relativePath) {
  const escapedPath = JSON.stringify(relativePath);
  return `export * from ${escapedPath};${hasDefaultExport ? `\nexport { default } from ${escapedPath};` : ""}\n`;
}

function dtsTemplate(filename, hasDefaultExport, relativePath, relativePathWithExtension) {
  return `${esmReexportTemplate(hasDefaultExport, relativePath)}${getDeclSourceMapComment(filename, relativePathWithExtension)}`;
}

function getReexportStatement(namedExports, source) {
  if (!namedExports.length) {
    // side-effects are important
    return `import ${source};`;
  } // rollup will say a chunk has a "*external-pkg" export when it has an export * from 'external-pkg'


  if (namedExports.some(exported => exported[0] === "*")) {
    return `export * from ${source};`;
  }

  return `export {\n  ${namedExports.join(",\n  ")}\n} from ${source};`;
}

function getJsDefaultForMjsFilepath(mjsPath) {
  return mjsPath.replace(/\.mjs$/, ".default.js");
}
function getDtsDefaultForMtsFilepath(mjsPath) {
  return mjsPath.replace(/\.d\.mts$/, ".default.d.ts");
}
function jsDefaultForMjsTemplate(relativePath) {
  return `exports._default = require(${JSON.stringify(relativePath)}).default;\n`;
}
function dtsDefaultForDmtsTemplate(relativePath) {
  return `export { default as _default } from ${JSON.stringify(relativePath)}\n`;
}
function mjsTemplate(exports, relativePath, mjsPath) {
  const escapedPath = JSON.stringify(relativePath);
  const nonDefaultExports = exports.filter(name => name !== "default");
  const hasDefaultExport = exports.length !== nonDefaultExports.length;
  return `${getReexportStatement(nonDefaultExports, escapedPath)}\n${hasDefaultExport ? `export { _default as default } from ${JSON.stringify("./" + getJsDefaultForMjsFilepath(path.basename(mjsPath)))};\n` : ""}`;
} // the only reason we sometimes name exports explicitly in the mjs template is
// to avoid adding __esModule as an export, this doesn't apply to the .d.mts
// since __esModule doesn't exist in declaration files
// just doing export * is nice because it means we don't have to bother
// getting the type-only exports

function dmtsTemplate(filename, hasDefaultExport, relativePath, relativePathWithExtension) {
  return `export * from ${JSON.stringify(relativePath)};\n${hasDefaultExport ? `export { _default as default } from ${JSON.stringify("./" + path.basename(filename).replace(/\.d\.mts$/, ".default.js"))};\n` : ""}${getDeclSourceMapComment(filename, relativePathWithExtension)}`;
}

function getDeclSourceMapComment(dtsFilename, relativePathWithExtension) {
  return `//# sourceMappingURL=data:application/json;charset=utf-8;base64,${Buffer.from(JSON.stringify({
    version: 3,
    file: dtsFilename,
    sourceRoot: "",
    sources: [relativePathWithExtension],
    names: [],
    mappings: "AAAA"
  })).toString("base64")}\n`;
}

function parseImportConditionDefaultExportOption(value, name) {
  if (value === "default" || value === "namespace") {
    return value;
  }

  throw new FatalError('the "preconstruct.exports.importConditionDefaultExport" field must be set to "default" or "namespace" if it is present', name);
}

function getFieldsUsedInEntrypoints(descriptors) {
  const fields = new Set(["main"]);

  for (let descriptor of descriptors) {
    if (descriptor.contents !== undefined) {
      let parsed = parseJson(descriptor.contents, descriptor.filename);

      for (let field of ["module", "umd:main", "browser"]) {
        const value = parsed[field];

        if (value !== undefined) {
          fields.add(field);
        }
      }
    }
  }

  return fields;
}

function getPlainEntrypointContent(pkg, fields, entrypointDir, indent) {
  const obj = {};
  const minimalEntrypoint = {
    hasModuleField: fields.has("module"),
    name: getEntrypointName(pkg, entrypointDir),
    package: pkg
  };

  for (const field of fields) {
    obj[field] = validFieldsForEntrypoint[field](minimalEntrypoint);
  }

  return JSON.stringify(obj, null, indent) + "\n";
}

function createEntrypoints(pkg, descriptors) {
  let fields = getFieldsUsedInEntrypoints(descriptors);
  return Promise.all(descriptors.map(async ({
    filename,
    contents,
    hasAccepted,
    sourceFile
  }) => {
    if (pkg.isTypeModule()) {
      if (contents !== undefined && pkg.path !== filename) {
        if (!hasAccepted) {
          const entrypointName = getEntrypointName(pkg, path__default.dirname(filename));
          let shouldDeleteEntrypointPkgJson = await confirms.deleteEntrypointPkgJson({
            name: entrypointName
          });

          if (!shouldDeleteEntrypointPkgJson) {
            throw new FatalError("this package has an entrypoint package.json but the typeModule feature is enabled, please remove the package.json", pkg.name);
          }
        }

        await fs.remove(filename);
        const contents = await fs.readdir(path__default.dirname(filename));

        if (contents.length === 0 || contents.length === 1 && contents[0] === "dist") {
          await fsPromises.rm(path__default.dirname(filename), {
            recursive: true
          });
        }
      }

      return new Entrypoint(filename, getPlainEntrypointContent(pkg, fields, path__default.dirname(filename), pkg.indent), pkg, sourceFile);
    }

    if (contents === undefined) {
      if (!hasAccepted) {
        const entrypointName = getEntrypointName(pkg, path__default.dirname(filename));
        let shouldCreateEntrypointPkgJson = await confirms.createEntrypointPkgJson({
          name: entrypointName
        });

        if (!shouldCreateEntrypointPkgJson) {
          throw new FatalError(errors$1.noEntrypointPkgJson, entrypointName);
        }
      }

      contents = getPlainEntrypointContent(pkg, fields, path__default.dirname(filename), pkg.indent);
      await fs.outputFile(filename, contents);
    }

    return new Entrypoint(filename, contents, pkg, sourceFile);
  }));
}

class Package extends Item {
  constructor(...args) {
    super(...args);

    _defineProperty(this, "project", void 0);

    _defineProperty(this, "entrypoints", void 0);

    _defineProperty(this, "_parsedImportsGroups", void 0);
  }

  get configEntrypoints() {
    if (this.json.preconstruct.entrypoints === undefined) {
      return ["index.{js,jsx,ts,tsx}"];
    }

    if (Array.isArray(this.json.preconstruct.entrypoints) && this.json.preconstruct.entrypoints.every(x => typeof x === "string")) {
      return this.json.preconstruct.entrypoints;
    }

    throw new FatalError("The entrypoints option for this packages is not an array of globs", this.name);
  }

  static async create(directory, project, isFix) {
    let filePath = path__default.join(directory, "package.json");
    let contents = await fs.readFile(filePath, "utf-8");
    let pkg = new Package(filePath, contents, project._jsonDataByPath);
    pkg.project = project;
    let entrypoints = await fastGlob(pkg.configEntrypoints, {
      cwd: path__default.join(pkg.directory, "src"),
      onlyFiles: true,
      absolute: true
    }); // sorting the entrypoints is important since we want to have something consistent
    // to write into the `exports` field and file systems don't guarantee an order

    entrypoints = [...entrypoints.sort((a, b) => {
      // shortest entrypoints first since shorter entrypoints
      // are generally more commonly used
      const comparison = a.length - b.length;
      if (comparison !== 0) return comparison; // then .sort's default behaviour because we just need something stable

      if (a < b) return -1;
      if (b > a) return 1;
      return 0;
    })];

    if (!entrypoints.length) {
      let oldEntrypoints = await fastGlob(pkg.configEntrypoints, {
        cwd: pkg.directory,
        onlyDirectories: true,
        absolute: true
      });

      if (oldEntrypoints.length) {
        throw new FatalError("this package has no entrypoints but it does have some using v1's entrypoints config, please see the the changelog for how to upgrade", pkg.name);
      }
    }

    pkg.entrypoints = await Promise.all(entrypoints.map(async sourceFile => {
      if (!/\.[tj]sx?$/.test(sourceFile)) {
        throw new FatalError(`entrypoint source files must end in .js, .jsx, .ts or .tsx but ${path__default.relative(pkg.directory, sourceFile)} does not`, pkg.name);
      }

      if (!normalizePath(sourceFile).includes(normalizePath(path__default.join(pkg.directory, "src")))) {
        throw new FatalError(`entrypoint source files must be inside of the src directory of a package but ${normalizePath(path__default.relative(pkg.directory, sourceFile))} is not`, pkg.name);
      }

      let directory = path__default.join(pkg.directory, path__default.resolve(sourceFile).replace(path__default.join(pkg.directory, "src"), "").replace(/\.[tj]sx?$/, ""));

      if (path__default.basename(directory) === "index") {
        directory = path__default.dirname(directory);
      }

      let filename = path__default.join(directory, "package.json");
      let contents = undefined;

      try {
        contents = await fs.readFile(filename, "utf-8");
      } catch (e) {
        if (e.code !== "ENOENT") {
          throw e;
        }
      }

      return {
        filename,
        contents,
        sourceFile,
        hasAccepted: isFix
      };
    })).then(async descriptors => {
      const globErrors = await getUselessGlobsThatArentReallyGlobsForNewEntrypoints(pkg.configEntrypoints, entrypoints, pkg.directory);

      if (globErrors.length) {
        let errors = globErrors.map(globError => {
          if (globError.exists) {
            return new FatalError(`specifies a entrypoint ${JSON.stringify(globError.glob)} but it is negated in the same config so it should be removed or the config should be fixed`, pkg.name);
          } else {
            return new FatalError(`specifies a entrypoint ${JSON.stringify(globError.glob)} but the file does not exist, please create it or fix the config`, pkg.name);
          }
        });

        if (errors.length) {
          throw new BatchError(errors);
        }
      }

      return createEntrypoints(pkg, descriptors);
    });
    const entrypointsWithSourcePath = new Map();

    for (const entrypoint of pkg.entrypoints) {
      if (entrypoint.json.preconstruct.source !== undefined) {
        throw new FatalError("The source option on entrypoints no longer exists, see the changelog for how to upgrade to the new entrypoints config", this.name);
      }

      if (entrypointsWithSourcePath.has(entrypoint.name)) {
        throw new FatalError(`this package has multiple source files for the same entrypoint of ${entrypoint.name} at ${normalizePath(path__default.relative(pkg.directory, entrypointsWithSourcePath.get(entrypoint.name)))} and ${normalizePath(path__default.relative(pkg.directory, entrypoint.source))}`, pkg.name);
      }

      entrypointsWithSourcePath.set(entrypoint.name, entrypoint.source);
    }

    return pkg;
  }

  setFieldOnEntrypoints(field) {
    this.entrypoints.forEach(entrypoint => {
      entrypoint.json = setFieldInOrder(entrypoint.json, field, validFieldsForEntrypoint[field](entrypoint));
    });
  }

  isTypeModule() {
    return this.project.experimentalFlags.typeModule && this.json.type === "module";
  }

  get name() {
    if (typeof this.json.name !== "string") {
      throw new FatalError("The name field on this package is not a string", this.directory);
    }

    return this.json.name;
  }

  get distFilenameStrategy() {
    if ("distFilenameStrategy" in this.project.json.preconstruct) {
      const written = this.project.json.preconstruct.distFilenameStrategy;

      if (written !== "full" && written !== "unscoped-package-name") {
        throw new FatalError(`distFilenameStrategy is defined in your Preconstruct config as ${JSON.stringify(written)} but the only accepted values are "full" and "unscoped-package-name"`, this.project.name);
      }

      return written;
    }

    return "full";
  }

  exportsFieldConfig() {
    if (this._parsedImportsGroups === undefined) {
      if (this.project.experimentalFlags.importsConditions) {
        this._parsedImportsGroups = parseImportsField(this.json.imports);
      } else {
        this._parsedImportsGroups = false;
      }
    }

    return parseExportsFieldConfig(this.json.preconstruct.exports, this.project.directory !== this.directory ? this.project.exportsFieldConfig() : undefined, this.name, this._parsedImportsGroups);
  }

}

function parseExportsFieldConfig(config, defaultExportFieldConfig, name, importsConditions) {
  var _defaultExportFieldCo;

  if (config === false || config === undefined && defaultExportFieldConfig === undefined) {
    return undefined;
  }

  const parsedConfig = {
    conditions: importsConditions === false ? {
      kind: "legacy",
      envs: new Set()
    } : {
      kind: "imports",
      groups: importsConditions
    },
    extra: {},
    importConditionDefaultExport: (_defaultExportFieldCo = defaultExportFieldConfig === null || defaultExportFieldConfig === void 0 ? void 0 : defaultExportFieldConfig.importConditionDefaultExport) !== null && _defaultExportFieldCo !== void 0 ? _defaultExportFieldCo : "namespace"
  };

  if (config === true || config === undefined) {
    return parsedConfig;
  }

  if (typeof config !== "object" || config === null || Array.isArray(config)) {
    throw new FatalError('the "preconstruct.exports" field must be a boolean or an object', name);
  }

  for (const [key, value] of Object.entries(config)) {
    if (key === "extra") {
      if (typeof value === "object" && value !== null && !Array.isArray(value)) {
        parsedConfig.extra = value;
      } else {
        throw new FatalError('the "preconstruct.exports.extra" field must be an object if it is present', name);
      }
    } else if (key === "envConditions") {
      if (parsedConfig.conditions.kind !== "legacy") {
        throw new FatalError('the "preconstruct.exports.envConditions" field is not supported when the imports conditions feature is enabled', name);
      }

      if (Array.isArray(value) && value.every(v => v === "worker" || v === "browser")) {
        parsedConfig.conditions.envs = new Set(value);

        if (parsedConfig.conditions.envs.size !== value.length) {
          throw new FatalError('the "preconstruct.exports.envConditions" field must not have duplicates', name);
        }
      } else {
        throw new FatalError('the "preconstruct.exports.envConditions" field must be an array containing zero or more of "worker" and "browser" if it is present', name);
      }
    } else if (key === "importConditionDefaultExport") {
      parsedConfig.importConditionDefaultExport = parseImportConditionDefaultExportOption(value, name);
    } else {
      throw new FatalError(`the "preconstruct.exports" field contains an unknown key "${key}"`, name);
    }
  }

  return parsedConfig;
}

async function validateIncludedFiles(pkg) {
  try {
    const rootDistDirectoryTestFilepath = path__default.join(pkg.directory, "dist", "preconstruct-test-file");
    const hasNoEntrypointAtRootOfPackage = pkg.entrypoints.every(entrypoint => entrypoint.directory !== pkg.directory);
    await Promise.all(pkg.entrypoints.map(async entrypoint => {
      if (pkg.isTypeModule() && entrypoint.name !== pkg.name) return;
      let filename = path__default.join(entrypoint.directory, "dist", "preconstruct-test-file");
      return fs.outputFile(filename, "test content");
    }).concat(hasNoEntrypointAtRootOfPackage ? fs.outputFile(rootDistDirectoryTestFilepath, "test content") : []));
    let packedFilesArr = await packlist({
      path: pkg.directory
    }); // Ensure consistent path separators. Without this, there's a mismatch between this result and the path it
    // checks on Windows. This value will have a forward slash (dist/preconstruct-test-file), whereas the value
    // of distFilePath below will have a backslash (dist\preconstruct-test-file). Obviously these two won't match,
    // so the distfile check will fail.

    let result = new Set(packedFilesArr.map(p => path__default.normalize(p))); // check that we're including the package.json and main file
    // TODO: add Flow and TS check and if they're ignored, don't write them

    let messages = [];
    pkg.entrypoints.forEach(entrypoint => {
      if (pkg.isTypeModule() && entrypoint.name !== pkg.name) return;
      let pkgJsonPath = path__default.relative(pkg.directory, path__default.resolve(entrypoint.directory, "package.json"));
      let distFilePath = path__default.relative(pkg.directory, path__default.resolve(entrypoint.directory, "dist", "preconstruct-test-file"));
      let entrypointName = path__default.relative(pkg.directory, entrypoint.directory);

      if (!result.has(pkgJsonPath)) {
        messages.push(`the entrypoint ${chalk.cyan(entrypointName)} isn't included in the published files for this package, please add it to the files field in the package's package.json`);
      } else if (!result.has(distFilePath)) {
        messages.push(`the dist directory ${entrypointName === "" ? "" : `for entrypoint ${chalk.cyan(entrypointName)} `}isn't included in the published files for this package, please add it to the files field in the package's package.json`);
      }
    });

    if (hasNoEntrypointAtRootOfPackage && !result.has(path__default.relative(pkg.directory, rootDistDirectoryTestFilepath))) {
      messages.push("the dist directory in the root of the package isn't included in the published files for this package, please add it to the files field in the package's package.json.\nthough this package does not have an entrypoint at the root of the package, preconstruct will write common chunks to the root dist directory so it must be included.");
    }

    if (messages.length) {
      throw new FatalError(messages.join("\n"), pkg.name);
    }
  } finally {
    await Promise.all(pkg.entrypoints.map(entrypoint => fs.remove(path__default.join(entrypoint.directory, "dist", "preconstruct-test-file"))));
  }
}

const allSettled = promises => Promise.all(promises.map(promise => promise.then(value => ({
  status: "fulfilled",
  value
}), reason => ({
  status: "rejected",
  reason
}))));

class Project extends Item {
  constructor(...args) {
    super(...args);

    _defineProperty(this, "packages", void 0);
  }

  get experimentalFlags() {
    let config = this.json.preconstruct.___experimentalFlags_WILL_CHANGE_IN_PATCH || {};

    if (config.distInRoot && !config.importsConditions) {
      throw new FatalError("distInRoot is not supported without importsConditions", this.name);
    }

    if (config.typeModule && !config.distInRoot) {
      throw new FatalError("typeModule is not supported without distInRoot", this.name);
    }

    return {
      logCompiledFiles: !!config.logCompiledFiles,
      keepDynamicImportAsDynamicImportInCommonJS: !!config.keepDynamicImportAsDynamicImportInCommonJS,
      importsConditions: !!config.importsConditions,
      distInRoot: !!config.distInRoot,
      typeModule: !!config.typeModule
    };
  }

  get configPackages() {
    if (this.json.preconstruct.packages === undefined) {
      return ["."];
    }

    if (Array.isArray(this.json.preconstruct.packages) && this.json.preconstruct.packages.every(x => typeof x === "string")) {
      return this.json.preconstruct.packages;
    }

    throw new FatalError("The packages option for this project is not an array of globs", this.name);
  }

  static async create(_directory, isFix = false) {
    const directory = await fs.realpath.native(_directory);
    let filePath = path__default.join(directory, "package.json");
    let contents = await fs.readFile(filePath, "utf-8");
    let project = new Project(filePath, contents, new Map());
    project.packages = await project._packages(isFix);
    return project;
  }

  get name() {
    if (typeof this.json.name !== "string") {
      throw new FatalError("The name field on this project is not a string", this.directory);
    }

    return this.json.name;
  }

  async _packages(isFix) {
    // suport bolt later probably
    // maybe lerna too though probably not
    if (!this.json.preconstruct.packages && this.json.workspaces) {
      let workspaces;

      if (Array.isArray(this.json.workspaces)) {
        workspaces = this.json.workspaces;
      } else if (Array.isArray(this.json.workspaces.packages)) {
        workspaces = this.json.workspaces.packages;
      }

      let packages = await promptInput("what packages should preconstruct build?", this, workspaces.join(","));
      this.json.preconstruct.packages = packages.split(",");
      await this.save();
    }

    let filenames = await fastGlob(this.configPackages, {
      cwd: this.directory,
      onlyDirectories: true,
      absolute: true
    });
    let packages = [];
    await Promise.all(filenames.map(async x => {
      try {
        packages.push((await Package.create(x, this, isFix)));
      } catch (err) {
        if (err.code === "ENOENT" && err.path === path__default.join(x, "package.json")) {
          return;
        }

        throw err;
      }
    }));
    const errored = (await allSettled(packages.map(pkg => validateIncludedFiles(pkg)))).find(result => result.status === "rejected");

    if (errored) {
      // TS can't refine type based on .find predicate
      throw errored.reason;
    }

    return packages;
  }

  exportsFieldConfig() {
    const exportsFieldConfig = this.json.preconstruct.exports;

    if (exportsFieldConfig === false || exportsFieldConfig === undefined) {
      return undefined;
    }

    let importConditionDefaultExport = "namespace";

    if (exportsFieldConfig === true) {
      return {
        importConditionDefaultExport
      };
    }

    if (typeof exportsFieldConfig !== "object" || exportsFieldConfig === null || Array.isArray(exportsFieldConfig)) {
      throw new FatalError('the "preconstruct.exports" field must be a boolean or an object', this.name);
    }

    for (const [key, val] of Object.entries(exportsFieldConfig)) {
      if (key === "importConditionDefaultExport") {
        importConditionDefaultExport = parseImportConditionDefaultExportOption(val, this.name);
        continue;
      }

      if (key === "extra" || key === "envConditions") {
        throw new FatalError(`the "preconstruct.exports.${key}" field can only be configured at the package level`, this.name);
      }

      throw new FatalError(`the "preconstruct.exports" field contains an unknown key "${key}"`, this.name);
    }

    return {
      importConditionDefaultExport
    };
  }

}

let keys$1 = Object.keys;
let unsafeRequire$1 = require;
function validatePackage(pkg) {
  if (pkg.entrypoints.length === 0) {
    throw new FatalError(errors$1.noEntrypoints, pkg.name);
  }

  let fields = {
    // main is intentionally not here, since it's always required
    // it will be validated in validateEntrypoint and the case
    // which this function validates will never happen
    module: pkg.entrypoints[0].json.module !== undefined,
    "umd:main": pkg.entrypoints[0].json["umd:main"] !== undefined,
    browser: pkg.entrypoints[0].json.browser !== undefined // "exports" is not here because it is not like these fields, it exists on a package, not an entrypoint

  };
  const exportsFieldConfig = pkg.exportsFieldConfig();

  if (exportsFieldConfig) {
    if (!fields.module && !pkg.isTypeModule()) {
      throw new FixableError(errors$1.noModuleFieldWithExportsField, pkg.name);
    }

    if (exportsFieldConfig.conditions.kind === "legacy") {
      const hasField = fields.browser;
      const hasCondition = exportsFieldConfig.conditions.envs.has("browser");

      if (hasField && !hasCondition) {
        throw new FixableError(errors$1.missingBrowserConditionWithFieldPresent, pkg.name);
      }

      if (!hasField && hasCondition) {
        throw new FixableError(errors$1.missingBrowserFieldWithConditionPresent, pkg.name);
      }
    }
  }

  if (!isFieldValid.exports(pkg)) {
    throw new FixableError(errors$1.invalidField("exports", pkg.json.exports, exportsField(pkg)), pkg.name);
  }

  if (pkg.isTypeModule()) {
    return;
  }

  pkg.entrypoints.forEach(entrypoint => {
    keys$1(fields).forEach(field => {
      if (entrypoint.json[field] && !fields[field]) {
        throw new FixableError(`${entrypoint.name} has a ${field} build but ${pkg.entrypoints[0].name} does not have a ${field} build. Entrypoints in a package must either all have a particular build type or all not have a particular build type.`, pkg.name);
      }

      if (!entrypoint.json[field] && fields[field]) {
        throw new FixableError(`${pkg.entrypoints[0].name} has a ${field} build but ${entrypoint.name} does not have a ${field} build. Entrypoints in a package must either all have a particular build type or all not have a particular build type.`, pkg.name);
      }
    });
  }); // TODO: do this well

  if (fields["umd:main"]) {
    // this is a sorta naive check
    // but it's handling the most common case
    // i don't think it's worth implementing this well at this exact moment
    // because i'm guessing doing it well would cause more problems than it would solve
    // this will likely change in the future
    let sortaAllDeps = new Set([...(pkg.json.peerDependencies ? Object.keys(pkg.json.peerDependencies) : []), ...(pkg.json.dependencies ? Object.keys(pkg.json.dependencies) : [])]);

    for (let depName in pkg.json.dependencies) {
      let depPkgJson;

      try {
        depPkgJson = unsafeRequire$1(resolveFrom(pkg.directory, depName + "/package.json"));
      } catch (err) {
        // ideally we'd resolve the packages ignoring the exports field but emitting
        // the peer dependency error thing below isn't that important
        // and having this be not broken for now is better
        if (err.code === "ERR_PACKAGE_PATH_NOT_EXPORTED") {
          continue;
        }

        throw err;
      }

      if (depPkgJson.peerDependencies) {
        for (let pkgName in depPkgJson.peerDependencies) {
          if (!sortaAllDeps.has(pkgName)) {
            throw new FatalError(`the package ${chalk.blue(pkg.name)} depends on ${chalk.blue(depName)} which has a peerDependency on ${chalk.blue(pkgName)} but ${chalk.blue(pkgName)} is not specified in the dependencies or peerDependencies of ${chalk.blue(pkg.name)}. please add ${chalk.blue(pkgName)} to the dependencies or peerDependencies of ${chalk.blue(pkg.name)}`, pkg.name);
          }
        }
      }
    }
  }
}

// just does validation
// used in build and watch

const isFieldValid = {
  main(entrypoint) {
    return entrypoint.json.main === validFieldsForEntrypoint.main(entrypoint);
  },

  module(entrypoint) {
    return entrypoint.json.module === validFieldsForEntrypoint.module(entrypoint);
  },

  "umd:main"(entrypoint) {
    return entrypoint.json["umd:main"] === validFieldsForEntrypoint["umd:main"](entrypoint);
  },

  browser(entrypoint) {
    return equal(entrypoint.json.browser, validFieldsForEntrypoint.browser(entrypoint));
  },

  exports(pkg) {
    const generated = exportsField(pkg);

    if (generated === undefined) {
      return true;
    } // JSON.stringify to make sure conditions are in proper order


    return JSON.stringify(pkg.json.exports) === JSON.stringify(generated);
  }

};
function isUmdNameSpecified(entrypoint) {
  return typeof entrypoint.json.preconstruct.umdName === "string";
}
let projectsShownOldDistNamesInfo = new WeakSet();

function validateEntrypoint(entrypoint, log) {
  if (log) {
    info(infos.validEntrypoint, entrypoint.name);
  }

  if (entrypoint.package.isTypeModule()) {
    return;
  }

  const fatalErrors = [];

  for (const field of ["main", "module", "umd:main", "browser"]) {
    if (field !== "main" && entrypoint.json[field] === undefined) {
      continue;
    }

    if (!isFieldValid[field](entrypoint)) {
      let isUsingOldDistFilenames;
      let prevDistFilenameStrategy = entrypoint.package.project.json.preconstruct.distFilenameStrategy;

      try {
        entrypoint.package.project.json.preconstruct.distFilenameStrategy = "unscoped-package-name";
        isUsingOldDistFilenames = validFieldsForEntrypoint[field](entrypoint) === entrypoint.json[field];
      } finally {
        if (prevDistFilenameStrategy === undefined) {
          delete entrypoint.package.project.json.preconstruct.distFilenameStrategy;
        } else {
          entrypoint.package.project.json.preconstruct.distFilenameStrategy = prevDistFilenameStrategy;
        }
      }

      if (isUsingOldDistFilenames && !projectsShownOldDistNamesInfo.has(entrypoint.package.project)) {
        projectsShownOldDistNamesInfo.add(entrypoint.package.project);
        info(`it looks like you're using the dist filenames of Preconstruct v1, the default dist filename strategy has changed in v2`);
        info(`you can run ${chalk.green("preconstruct fix")} to use the new dist filenames`);
        info('if you want to keep the dist filename strategy of v1, add `"distFilenameStrategy": "unscoped-package-name"` to the Preconstruct config in your root package.json');
      }

      fatalErrors.push( // they're both fixable but we don't want the message about running preconstruct fix if they're using the old dist file names since we have a custom message
      new (isUsingOldDistFilenames ? FatalError : FixableError)(errors$1.invalidField(field, entrypoint.json[field], validFieldsForEntrypoint[field](entrypoint)), entrypoint.name));
    }

    if (field === "umd:main" && !isUmdNameSpecified(entrypoint)) {
      fatalErrors.push(new FixableError(errors$1.umdNameNotSpecified, entrypoint.name));
    }

    if (log && !fatalErrors.length) {
      info(infos.validField(field), entrypoint.name);
    }
  }

  if (fatalErrors.length) {
    throw new BatchError(fatalErrors);
  }
}

const FORMER_FLAGS_THAT_ARE_ENABLED_NOW = new Set(["newEntrypoints", "newDistFilenames", "newProcessEnvNodeEnvReplacementStrategyAndSkipTerserOnCJSProdBuild", "exports", "onlyEmitUsedTypeScriptDeclarations"]);
const EXPERIMENTAL_FLAGS = new Set(["logCompiledFiles", "keepDynamicImportAsDynamicImportInCommonJS", "importsConditions", "distInRoot", "typeModule"]);
function validateProject(project, log = false) {
  let errors = [];

  if (project.json.preconstruct.___experimentalFlags_WILL_CHANGE_IN_PATCH) {
    Object.keys(project.json.preconstruct.___experimentalFlags_WILL_CHANGE_IN_PATCH).forEach(key => {
      if (FORMER_FLAGS_THAT_ARE_ENABLED_NOW.has(key)) {
        errors.push(new FixableError(`The behaviour from the experimental flag ${JSON.stringify(key)} is the current behaviour now, the flag should be removed`, project.name));
      } else if (!EXPERIMENTAL_FLAGS.has(key)) {
        errors.push(new FatalError(`The experimental flag ${JSON.stringify(key)} in your config does not exist`, project.name));
      }
    });
  }

  for (let pkg of project.packages) {
    try {
      validatePackage(pkg);
    } catch (err) {
      if (err instanceof BatchError) {
        errors.push(...err.errors);
      } else if (err instanceof FatalError) {
        errors.push(err);
      } else {
        throw err;
      }
    }

    for (let entrypoint of pkg.entrypoints) {
      try {
        validateEntrypoint(entrypoint, log);
      } catch (err) {
        if (err instanceof BatchError) {
          errors.push(...err.errors);
        } else if (err instanceof FatalError) {
          errors.push(err);
        } else {
          throw err;
        }
      }
    }
  }

  if (errors.length) {
    if (errors.length === 1) {
      throw errors[0];
    }

    throw new BatchError(errors);
  }
}
async function validate(directory) {
  let project = await Project.create(directory);
  validateProject(project, true);
  success(successes.validProject);
}

async function doInit(pkg) {
  if (pkg.entrypoints.every(entrypoint => isFieldValid.main(entrypoint))) {
    info(infos.validField("main"), pkg.name);
  } else {
    let canWriteMainField = await confirms.writeMainField(pkg);

    if (!canWriteMainField) {
      throw new FatalError(errors$1.deniedWriteMainField, pkg.name);
    }

    pkg.setFieldOnEntrypoints("main");
  }

  let allEntrypointsAreMissingAModuleField = pkg.entrypoints.every(entrypoint => entrypoint.json.module === undefined);
  let someEntrypointsAreNotValid = pkg.entrypoints.some(entrypoint => !isFieldValid.module(entrypoint));

  if (allEntrypointsAreMissingAModuleField || someEntrypointsAreNotValid) {
    let canWriteModuleField = await confirms.writeModuleField(pkg);

    if (canWriteModuleField) {
      pkg.setFieldOnEntrypoints("module");
    } else if (!allEntrypointsAreMissingAModuleField) {
      throw new FixableError(errors$1.fieldMustExistInAllEntrypointsIfExistsDeclinedFixDuringInit("module"), pkg.name);
    }
  } else {
    info(infos.validField("module"), pkg.name);
  }

  let someEntrypointsHaveAMaybeInvalidUmdBuild = pkg.entrypoints.some(entrypoint => entrypoint.json["umd:main"] !== undefined);
  let someUmdMainFieldsAreInvalid = pkg.entrypoints.some(entrypoint => !isFieldValid["umd:main"](entrypoint));
  let someUmdNamesAreNotSpecified = pkg.entrypoints.some(entrypoint => !isUmdNameSpecified(entrypoint));

  if (someEntrypointsHaveAMaybeInvalidUmdBuild && (someUmdMainFieldsAreInvalid || someUmdNamesAreNotSpecified)) {
    let shouldWriteUMDBuilds = await confirms.fixUmdBuild(pkg);

    if (shouldWriteUMDBuilds) {
      pkg.setFieldOnEntrypoints("umd:main");

      for (let entrypoint of pkg.entrypoints) {
        let umdName = await promptInput(inputs.getUmdName, entrypoint);
        entrypoint.json.preconstruct.umdName = umdName;
      }
    } else {
      throw new FixableError(errors$1.fieldMustExistInAllEntrypointsIfExistsDeclinedFixDuringInit("umd:main"), pkg.name);
    }
  }

  let someEntrypointsHaveABrowserField = pkg.entrypoints.some(entrypoint => entrypoint.json.browser !== undefined);
  let someEntrypointsHaveAnInvalidBrowserField = pkg.entrypoints.some(entrypoint => !isFieldValid.browser(entrypoint));

  if (someEntrypointsHaveABrowserField && someEntrypointsHaveAnInvalidBrowserField) {
    let shouldFixBrowserField = await confirms.fixBrowserField(pkg);

    if (shouldFixBrowserField) {
      pkg.setFieldOnEntrypoints("browser");
    } else {
      throw new FixableError(errors$1.fieldMustExistInAllEntrypointsIfExistsDeclinedFixDuringInit("browser"), pkg.name);
    }
  }

  await Promise.all(pkg.entrypoints.map(x => x.save()));
}

async function init(directory) {
  let project = await Project.create(directory);
  await Promise.all(project.packages.map(doInit));
  success("initialised project!");
}

const pattern = /from (["'])@babel\/runtime(|-corejs[23])\/helpers\/(\w+)["']/g;
const requireWithEsmPattern = /require\((["'])@babel\/runtime(|-corejs[23])\/helpers\/esm\/(\w+)["']\)/g;
function rewriteBabelRuntimeHelpers() {
  return {
    name: "rewrite-babel-runtime-helpers",

    renderChunk(code, chunkInfo, {
      format
    }) {
      if (format === "es") {
        return code.replace(pattern, (_, quote, maybeCorejsBit, path) => {
          return `from ${quote}@babel/runtime${maybeCorejsBit}/helpers/esm/${path}${quote}`;
        });
      }

      if (format === "cjs") {
        return code.replace(requireWithEsmPattern, (_, quote, maybeCorejsBit, path) => {
          return `require(${quote}@babel/runtime${maybeCorejsBit}/helpers/${path}${quote})`;
        });
      }

      return null;
    }

  };
}

function getModuleSpecifier(node, typescript) {
  // import/export { x } from "x"
  const isImportDeclaration = typescript.isImportDeclaration(node);

  if ((isImportDeclaration || typescript.isExportDeclaration(node)) && node.moduleSpecifier !== undefined && typescript.isStringLiteral(node.moduleSpecifier)) {
    return node.moduleSpecifier;
  } // type x = import('a').Blah


  if (typescript.isImportTypeNode(node) && typescript.isLiteralTypeNode(node.argument) && typescript.isStringLiteral(node.argument.literal)) {
    return node.argument.literal;
  } // import x = require("x")


  if (typescript.isExternalModuleReference(node) && typescript.isStringLiteral(node.expression)) {
    return node.expression;
  }
}

function getDiagnosticsHost(ts, projectDir) {
  return {
    getCanonicalFileName: x => ts.sys.useCaseSensitiveFileNames ? x : x.toLowerCase(),
    getCurrentDirectory: () => projectDir,
    getNewLine: () => EOL
  };
}
function loadTypeScript(packageDir, projectDir, pkgName) {
  try {
    return require(resolveFrom(packageDir, "typescript"));
  } catch (err) {
    if (err.code === "MODULE_NOT_FOUND") {
      try {
        // if people have typescript installed at the their project and they're using Yarn PnP,
        // typescript won't be resolvable at the package level but it will be resolvable at the project level
        // (note this will only happen with PnP)
        return require(resolveFrom(projectDir, "typescript"));
      } catch (err) {
        throw new FatalError("an entrypoint source file ends with the .ts or .tsx extension but the typescript module could not be resolved from the project directory, please install it.", pkgName);
      }
    }

    throw err;
  }
}

function weakMemoize(func) {
  let cache = new WeakMap();
  return arg => {
    if (cache.has(arg)) {
      return cache.get(arg);
    }

    let ret = func(arg);
    cache.set(arg, ret);
    return ret;
  };
}

function memoize(fn) {
  const cache = new Map();
  return arg => {
    if (!cache.has(arg)) cache.set(arg, fn(arg));
    return cache.get(arg);
  };
}

async function nonMemoizedGetProgram(typescript, configFileName) {
  let configFileContents = await fs.readFile(configFileName, "utf8");
  const result = typescript.parseConfigFileTextToJson(configFileName, configFileContents);
  let thing = typescript.parseJsonConfigFileContent(result.config, typescript.sys, process.cwd(), undefined, configFileName);
  thing.options.outDir = undefined;
  thing.options.declarationDir = undefined;
  thing.options.declaration = true;
  thing.options.emitDeclarationOnly = true;
  thing.options.noEmit = false;
  let program = typescript.createProgram(thing.fileNames, thing.options);
  return {
    options: thing.options,
    program
  };
}

let memoizedGetProgram = weakMemoize(typescript => memoize(async configFileName => {
  return nonMemoizedGetProgram(typescript, configFileName);
}));
async function getProgram(dirname, pkgName, ts) {
  let configFileName = ts.findConfigFile(dirname, ts.sys.fileExists);

  if (!configFileName) {
    throw new FatalError("an entrypoint source file ends with the .ts or tsx extension but no TypeScript config exists, please create one.", pkgName);
  } // if the tsconfig is inside the package directory, let's not memoize getting the ts service
  // since it'll only ever be used once
  // and if we keep it, we could run out of memory for large projects
  // if the tsconfig _isn't_ in the package directory though, it's probably fine to memoize it
  // since it should just be a root level tsconfig


  return normalizePath(configFileName) === normalizePath(path__default.join(dirname, "tsconfig.json")) ? nonMemoizedGetProgram(ts, configFileName) : memoizedGetProgram(ts)(configFileName);
}
const dtsFileRegex = /\.d\.[cm]?ts$/;
function getDeclarationsForFile(filename, typescript, program, normalizedPkgDir, projectDir, diagnosticsHost,
/** This will only be called once per unique module specifier in a file */
visitModuleSpecifier) {
  const cachedVisitModuleSpecifier = memoize(visitModuleSpecifier !== null && visitModuleSpecifier !== void 0 ? visitModuleSpecifier : x => x);
  const sourceFile = program.getSourceFile(typescript.sys.useCaseSensitiveFileNames ? filename : filename.toLowerCase());

  if (!sourceFile) {
    throw new Error(`Could not find source file at ${filename} in TypeScript declaration generation, this is likely a bug in Preconstruct`);
  }

  if (dtsFileRegex.test(filename)) {
    let content = sourceFile.text;

    if (visitModuleSpecifier) {
      const magicString = new MagicString(content);

      const visitor = node => {
        const moduleSpecifier = getModuleSpecifier(node, typescript);

        if (moduleSpecifier) {
          const replaced = cachedVisitModuleSpecifier(moduleSpecifier.text);

          if (replaced !== moduleSpecifier.text) {
            magicString.update(moduleSpecifier.getStart(sourceFile, false), moduleSpecifier.getEnd(), JSON.stringify(replaced));
          }
        }

        typescript.forEachChild(node, visitor);
      };

      typescript.forEachChild(sourceFile, visitor);
      content = magicString.toString();
    }

    return {
      types: {
        name: filename.replace(normalizedPkgDir, normalizePath(path__default.join(normalizedPkgDir, "dist", "declarations"))),
        content
      },
      filename
    };
  }

  const emitted = {};
  const otherEmitted = [];
  const {
    diagnostics
  } = program.emit(sourceFile, (name, text) => {
    if (name.endsWith(".d.ts")) {
      emitted.types = {
        name: name.replace(normalizedPkgDir, normalizePath(path__default.join(normalizedPkgDir, "dist", "declarations"))),
        content: text
      };
    } else if (name.endsWith(".d.ts.map")) {
      emitted.map = {
        name: name.replace(normalizedPkgDir, normalizePath(path__default.join(normalizedPkgDir, "dist", "declarations"))),
        content: text
      };
    } else {
      otherEmitted.push({
        name,
        text
      });
    }
  }, undefined, true, {
    afterDeclarations: [context => node => {
      if (!visitModuleSpecifier) {
        return node;
      }

      const replacedNodes = new Map();

      const visitor = node => {
        if (typescript.isStringLiteral(node) && replacedNodes.has(node)) {
          return replacedNodes.get(node);
        }

        const literal = getModuleSpecifier(node, typescript);

        if (literal) {
          const replaced = cachedVisitModuleSpecifier(literal.text);

          if (replaced !== literal.text) {
            replacedNodes.set(literal, typescript.factory.createStringLiteral(replaced));
          }
        }

        return typescript.visitEachChild(node, visitor, context);
      };

      return typescript.visitEachChild(node, visitor, context);
    }]
  });

  if (!emitted.types || diagnostics.length) {
    throw new FatalError(`Generating TypeScript declarations for ${normalizePath(path__default.relative(projectDir, filename))} failed:\n${typescript.formatDiagnosticsWithColorAndContext(diagnostics, diagnosticsHost)}${otherEmitted.length ? `\n\nTypeScript emitted other files when attempting to emit .d.ts files:\n${otherEmitted.map(x => `${x.name}\n\n${x.text}`).join("\n\n")}` : ""}`, "");
  }

  return {
    types: emitted.types,
    map: emitted.map,
    filename
  };
}
function overwriteDeclarationMapSourceRoot(content, actualSourceRoot) {
  const src = JSON.parse(content);
  src.sourceRoot = actualSourceRoot;
  return JSON.stringify(src);
}

function replaceExt(filename) {
  return filename.replace(/(\.d)?\.([cm]?ts|tsx)$/, (match, p1, p2) => {
    if (p2 === ".cts") return ".cjs";
    if (p2 === ".mts") return ".mjs";
    return ".js";
  });
}

function getDeclarationsWithImportedModuleSpecifiersReplacing(typescript, program, normalizedPkgDir, projectDir, resolveModuleName, resolvedEntrypointSources) {
  const depQueue = new Set(resolvedEntrypointSources);
  const diagnosticsHost = getDiagnosticsHost(typescript, projectDir);
  const normalizedPkgDirNodeModules = normalizePath(path__default.join(normalizedPkgDir, "node_modules"));
  const emitted = [];

  for (const filename of depQueue) {
    const handleImport = imported => {
      const resolvedModule = resolveModuleName(imported, filename);

      if (!resolvedModule || !resolvedModule.resolvedFileName.startsWith(normalizedPkgDir) || resolvedModule.resolvedFileName.startsWith(normalizedPkgDirNodeModules)) {
        return imported;
      }

      depQueue.add(resolvedModule.resolvedFileName);
      let forImport = replaceExt(normalizePath(path__default.relative(path__default.dirname(filename), resolvedModule.resolvedFileName)));

      if (!forImport.startsWith("../")) {
        forImport = `./${forImport}`;
      }

      return forImport;
    };

    const output = getDeclarationsForFile(filename, typescript, program, normalizedPkgDir, projectDir, diagnosticsHost, handleImport);
    emitted.push(output);
  }

  return emitted;
}

let isTsPath = source => /\.tsx?/.test(source);
function typescriptDeclarations(pkg) {
  return {
    name: "typescript-declarations",

    async generateBundle(opts, bundle) {
      if (opts.format !== "cjs" && !pkg.isTypeModule()) return; // we want do a naive check first and go into
      // so that we can avoid some extra fs operations if there is say some .ts entrypoints
      // and some .js entrypoints with a .d.ts

      if (!pkg.entrypoints.some(({
        source
      }) => isTsPath(source))) {
        const hasSomeDtsEntrypoints = (await Promise.all(pkg.entrypoints.map(async ({
          source
        }) => {
          try {
            await fs__default.stat(source.replace(/\.jsx?/, ".d.ts"));
          } catch (err) {
            if (err.code === "ENOENT") {
              return false;
            }

            throw err;
          }

          return true;
        }))).some(hasDtsForEntrypoint => hasDtsForEntrypoint);

        if (!hasSomeDtsEntrypoints) {
          return;
        }
      }

      const typescript = loadTypeScript(pkg.directory, pkg.project.directory, pkg.name);
      const {
        program,
        options
      } = await getProgram(pkg.directory, pkg.name, typescript);
      let normalizedDirname = normalizePath(pkg.directory);
      let moduleResolutionCache = typescript.createModuleResolutionCache(normalizedDirname, x => x, options);

      const resolveModule = (moduleName, containingFile) => {
        let {
          resolvedModule
        } = typescript.resolveModuleName(moduleName, containingFile, options, typescript.sys, moduleResolutionCache);
        return resolvedModule;
      };

      const entrypointSourceToTypeScriptSource = new Map(pkg.entrypoints.map(entrypoint => {
        const x = entrypoint.source;
        let resolvedModule = resolveModule(path__default.join(path__default.dirname(x), path__default.basename(x, path__default.extname(x))), pkg.directory);

        if (!resolvedModule) {
          throw new Error("This is an internal error, please open an issue if you see this: ts could not resolve module");
        }

        return [normalizePath(x), resolvedModule.resolvedFileName];
      }));
      const declarations = getDeclarationsWithImportedModuleSpecifiersReplacing(typescript, program, normalizedDirname, pkg.project.directory, resolveModule, [...entrypointSourceToTypeScriptSource.values()]);
      let srcFilenameToDtsFilenameMap = new Map();
      await Promise.all([...declarations].map(async output => {
        srcFilenameToDtsFilenameMap.set(normalizePath(output.filename), output.types.name);
        this.emitFile({
          type: "asset",
          fileName: path__default.relative(opts.dir, output.types.name),
          source: output.types.content
        });

        if (output.map) {
          const sourceRoot = normalizePath(path__default.dirname(path__default.relative(path__default.dirname(output.map.name), output.filename)));
          const source = overwriteDeclarationMapSourceRoot(output.map.content, sourceRoot);
          this.emitFile({
            type: "asset",
            fileName: path__default.relative(opts.dir, output.map.name),
            source
          });
        }
      }));

      for (const n in bundle) {
        var _pkg$exportsFieldConf;

        const file = bundle[n];

        if (file.type === "asset" || !file.isEntry || file.facadeModuleId == null) {
          continue;
        }

        const facadeModuleId = file.facadeModuleId;
        const typeScriptSource = entrypointSourceToTypeScriptSource.get(normalizePath(facadeModuleId));

        if (!typeScriptSource) {
          // will happen when only some entrypoints are TypeScript
          continue;
        }

        let dtsFilename = srcFilenameToDtsFilenameMap.get(normalizePath(typeScriptSource));

        if (!dtsFilename) {
          // a user should never be able to cause this to happen
          throw new FatalError(`no .d.ts file was found for the source at ${typeScriptSource}`, pkg.name);
        }

        let mainFieldPath = file.fileName.replace(/(?:\.prod)?\.js$/, "");
        let relativeToSource = normalizePath(path__default.relative(path__default.dirname(path__default.join(opts.dir, file.fileName)), dtsFilename.replace(/\.d\.ts$/, "")));

        if (!relativeToSource.startsWith(".")) {
          relativeToSource = `./${relativeToSource}`;
        }

        const dtsFileName = `${mainFieldPath}.d.ts`;
        const baseDtsFilename = path__default.basename(dtsFileName); // TODO: technically this is wrong because you could have a default type-only export
        // (though i doubt that is very common)

        const hasDefaultExport = file.exports.includes("default");
        const dtsFileSource = dtsTemplate(baseDtsFilename, hasDefaultExport, relativeToSource, `${relativeToSource}.d.ts`);
        this.emitFile({
          type: "asset",
          fileName: dtsFileName,
          source: dtsFileSource
        });

        if (((_pkg$exportsFieldConf = pkg.exportsFieldConfig()) === null || _pkg$exportsFieldConf === void 0 ? void 0 : _pkg$exportsFieldConf.importConditionDefaultExport) === "default" && !pkg.isTypeModule()) {
          const dmtsFilename = dtsFileName.replace(/\.d\.ts$/, ".d.mts");
          const basedmtsFilename = baseDtsFilename.replace(/\.d\.ts$/, ".d.mts");
          const sourceWithExtension = `${relativeToSource}.js`;
          this.emitFile({
            type: "asset",
            fileName: dmtsFilename,
            source: dmtsTemplate(basedmtsFilename, hasDefaultExport, sourceWithExtension, `${relativeToSource}.d.ts`)
          });

          if (hasDefaultExport) {
            this.emitFile({
              type: "asset",
              fileName: getDtsDefaultForMtsFilepath(dmtsFilename),
              source: dtsDefaultForDmtsTemplate(sourceWithExtension)
            });
          }
        }
      }
    }

  };
}

let tsExtensionPattern = /\.tsx?$/;

async function hasDtsFile(entrypoint) {
  try {
    const filename = entrypoint.source.replace(/\.jsx?/, ".d.ts");
    await fs.stat(filename);
    return true;
  } catch (err) {
    if (err.code !== "ENOENT") {
      throw err;
    }
  }

  return false;
} // technically we should consider three states 'no-default' | 'default' | 'type-only-default'
// but we don't handle that correctly for builds right now anyway and i don't think people are
// really doing type-only default exports so i'm not worrying about it right now


async function entrypointHasDefaultExport(entrypoint, content) {
  // this regex won't tell us that a module definitely has a default export
  // if it doesn't match though, it will tell us that the module
  // definitely _doesn't_ have a default export
  // we want to do this because a Babel parse is very expensive
  // so we want to avoid doing it unless we absolutely have to
  if (!/(export\s*{[^}]*default|export\s+(|\*\s+as\s+)default\s)/.test(content)) {
    return false;
  }

  const babel = _lazyRequireBabelCore();

  let ast = await babel.parseAsync(content, {
    filename: entrypoint.source,
    sourceType: "module",
    cwd: entrypoint.package.project.directory
  });

  for (let statement of ast.program.body) {
    if (statement.type === "ExportDefaultDeclaration" || statement.type === "ExportNamedDeclaration" && statement.specifiers.some(specifier => (specifier.type === "ExportDefaultSpecifier" || specifier.type === "ExportNamespaceSpecifier" || specifier.type === "ExportSpecifier") && specifier.exported.type === "Identifier" && specifier.exported.name === "default")) {
      return true;
    }
  }

  return false;
}
async function writeDevTSFiles(entrypoint, hasDefaultExport) {
  var _entrypoint$package$e;

  const dtsReexportFilename = path__default.join((entrypoint.package.project.experimentalFlags.distInRoot ? entrypoint.package : entrypoint).directory, "dist", getBaseDistName(entrypoint) + (entrypoint.package.isTypeModule() ? "" : ".cjs") + ".d.ts");
  const baseDtsFilename = path__default.basename(dtsReexportFilename);
  const relativePathWithExtension = normalizePath(path__default.relative(path__default.dirname(dtsReexportFilename), entrypoint.source));
  let promises = [fs.outputFile(dtsReexportFilename, dtsTemplate(baseDtsFilename, hasDefaultExport, relativePathWithExtension.replace(/\.tsx?$/, ""), relativePathWithExtension))];

  if (((_entrypoint$package$e = entrypoint.package.exportsFieldConfig()) === null || _entrypoint$package$e === void 0 ? void 0 : _entrypoint$package$e.importConditionDefaultExport) === "default" && !entrypoint.package.isTypeModule()) {
    const dmtsReexportFilename = path__default.join(entrypoint.directory, validFieldsForEntrypoint.main(entrypoint)).replace(/\.js$/, ".d.mts");
    const baseDmtsFilename = path__default.basename(dmtsReexportFilename);
    const ext = path__default.extname(relativePathWithExtension).slice(1);
    const mappedExt = {
      ts: "js",
      tsx: "js",
      mts: "mjs",
      cts: "cjs"
    }[ext];
    const pathToImport = mappedExt ? relativePathWithExtension.replace(new RegExp(`\\.${ext}$`), `.${mappedExt}`) : relativePathWithExtension;
    promises.push(fs.outputFile(dmtsReexportFilename, dmtsTemplate(baseDmtsFilename, hasDefaultExport, pathToImport, relativePathWithExtension)));

    if (hasDefaultExport) {
      promises.push(fs.outputFile(getDtsDefaultForMtsFilepath(dmtsReexportFilename), dtsDefaultForDmtsTemplate(pathToImport)));
    }
  }

  await Promise.all(promises);
}

async function writeDevFlowFile(entrypoint) {
  // so...
  // you might have noticed that this passes
  // hasExportDefault=false
  // and be thinking that default exports
  // but flow seems to be
  // then you might ask, if re-exporting the default
  // export isn't necessary, why do it for actual builds?
  // the reason is is that if preconstruct dev breaks because
  // of a new version of flow that changes this, that's mostly okay
  // because preconstruct dev can be fixed, a consumer can upgrade it
  // and then everything is fine but if a production build is broken
  // a consumer would have to do a new release and that's not ideal
  let cjsDistPath = path__default.join(entrypoint.directory, validFieldsForEntrypoint.main(entrypoint));
  await fs.writeFile(cjsDistPath + ".flow", flowTemplate(false, normalizePath(path__default.relative(path__default.dirname(cjsDistPath), entrypoint.source))));
}

async function dev(projectDir) {
  let project = await Project.create(projectDir);
  validateProject(project);
  info("project is valid!");
  await Promise.all(project.packages.map(async pkg => {
    const exportsFieldConfig = pkg.exportsFieldConfig();
    let distDirectory = path__default.join(pkg.directory, "dist");
    await fs.remove(distDirectory);
    await fs.ensureDir(distDirectory);
    return Promise.all(pkg.entrypoints.map(async entrypoint => {
      let hasDefaultExportPromise;
      const contentsPromise = fs.readFile(entrypoint.source, "utf8");

      const getHasDefaultExportPromise = () => {
        if (hasDefaultExportPromise === undefined) {
          hasDefaultExportPromise = contentsPromise.then(content => entrypointHasDefaultExport(entrypoint, content));
        }

        return hasDefaultExportPromise;
      };

      await cleanEntrypoint(entrypoint);
      let entrypointPromises = [(async () => {
        if ((await contentsPromise).includes("@flow")) {
          await writeDevFlowFile(entrypoint);
        }
      })(), (async () => {
        if (tsExtensionPattern.test(entrypoint.source) || (await hasDtsFile(entrypoint))) {
          await writeDevTSFiles(entrypoint, (await getHasDefaultExportPromise()));
        }
      })()];

      if (pkg.isTypeModule() && exportsFieldConfig && exportsFieldConfig.conditions.kind === "imports") {
        for (const conditions of exportsFieldConfig.conditions.groups.keys()) {
          entrypointPromises.push(fs.symlink(entrypoint.source, path__default.join(pkg.directory, getDistFilenameForConditionsWithTypeModule(entrypoint, conditions))));
        }

        return Promise.all(entrypointPromises);
      }

      const cjsTemplate = commonjsRequireHookTemplate(entrypoint);

      if ((exportsFieldConfig === null || exportsFieldConfig === void 0 ? void 0 : exportsFieldConfig.conditions.kind) === "imports") {
        for (const conditions of exportsFieldConfig.conditions.groups.keys()) {
          const distRoot = project.experimentalFlags.distInRoot ? pkg.directory : entrypoint.directory;
          entrypointPromises.push(fs.symlink(entrypoint.source, path__default.join(distRoot, getDistFilenameForConditions(entrypoint, conditions.concat("module")))), fs.writeFile(path__default.join(distRoot, getDistFilenameForConditions(entrypoint, conditions)), cjsTemplate));

          if (exportsFieldConfig.importConditionDefaultExport === "default") {
            entrypointPromises.push(getHasDefaultExportPromise().then(hasDefaultExport => {
              const filepath = path__default.join(entrypoint.package.directory, getDistFilenameForConditions(entrypoint, conditions).replace(/\.js$/, ".mjs"));
              const importPath = `./${getDistFilenameForConditions(entrypoint, conditions)}`;
              return Promise.all([fs.writeFile(filepath, mjsTemplate( // the * won't really do anything right now
              // since cjs-module-lexer won't find anything
              // but that could be fixed by adding fake things
              // to the .cjs.js file that look like exports to cjs-module-lexer
              // but don't actually add the exports at runtime like esbuild does
              // (it would require re-running dev when adding new named exports)
              hasDefaultExport ? ["default", "*other"] : ["*other"], importPath, filepath)), hasDefaultExport && fs.writeFile(getJsDefaultForMjsFilepath(filepath), jsDefaultForMjsTemplate(importPath))]);
            }));
          }
        }

        return Promise.all(entrypointPromises);
      }

      entrypointPromises.push(fs.writeFile(path__default.join(entrypoint.directory, validFieldsForEntrypoint.main(entrypoint)), cjsTemplate));

      if ((exportsFieldConfig === null || exportsFieldConfig === void 0 ? void 0 : exportsFieldConfig.importConditionDefaultExport) === "default") {
        entrypointPromises.push(getHasDefaultExportPromise().then(hasDefaultExport => {
          const filepath = path__default.join(entrypoint.package.directory, getExportsImportUnwrappingDefaultOutputPath(entrypoint));
          const importPath = `./${getBaseDistFilename(entrypoint, "cjs")}`;
          return Promise.all([fs.writeFile(filepath, mjsTemplate( // the * won't really do anything right now
          // since cjs-module-lexer won't find anything
          // but that could be fixed by adding fake things
          // to the .cjs.js file that look like exports to cjs-module-lexer
          // but don't actually add the exports at runtime like esbuild does
          // (it would require re-running dev when adding new named exports)
          hasDefaultExport ? ["default", "*other"] : ["*other"], importPath, filepath)), hasDefaultExport ? fs.writeFile(getJsDefaultForMjsFilepath(filepath), jsDefaultForMjsTemplate(importPath)) : undefined]);
        }));
      }

      if (entrypoint.json.module) {
        entrypointPromises.push(fs.symlink(entrypoint.source, path__default.join(entrypoint.directory, validFieldsForEntrypoint.module(entrypoint))));
      }

      if (exportsFieldConfig !== null && exportsFieldConfig !== void 0 && exportsFieldConfig.conditions.envs.has("worker")) {
        entrypointPromises.push(fs.symlink(entrypoint.source, path__default.join(pkg.directory, getExportsFieldOutputPath(entrypoint, "worker"))));
      }

      if (entrypoint.json.browser) {
        let browserField = validFieldsForEntrypoint.browser(entrypoint);

        for (let output of Object.values(browserField)) {
          entrypointPromises.push(fs.symlink(entrypoint.source, path__default.join(entrypoint.directory, output)));
        }
      }

      return Promise.all(entrypointPromises);
    }));
  }));
  success("created links!");
}

async function cleanEntrypoint(entrypoint) {
  if (entrypoint.package.name === entrypoint.name) return;
  let distDirectory = path__default.join(entrypoint.directory, "dist");
  await fs.remove(distDirectory);

  if (!entrypoint.package.project.experimentalFlags.distInRoot) {
    await fs.ensureDir(distDirectory);
  }
}

function commonjsRequireHookTemplate(entrypoint) {
  const distDirectory = path__default.join((entrypoint.package.project.experimentalFlags.distInRoot ? entrypoint.package : entrypoint).directory, "dist");
  let entrypointPath = normalizePath(path__default.relative(distDirectory, entrypoint.source));
  return `"use strict";
// this file might look strange and you might be wondering what it's for
// it's lets you import your source files by importing this entrypoint
// as you would import it if it was built with preconstruct build
// this file is slightly different to some others though
// it has a require hook which compiles your code with Babel
// this means that you don't have to set up @babel/register or anything like that
// but you can still require this module and it'll be compiled

// this bit of code imports the require hook and registers it
let unregister = require(${JSON.stringify(normalizePath(path__default.relative(distDirectory, path__default.dirname(require.resolve("@preconstruct/hook")))))}).___internalHook(typeof __dirname === 'undefined' ? undefined : __dirname, ${JSON.stringify(normalizePath(path__default.relative(distDirectory, entrypoint.package.project.directory)))}, ${JSON.stringify(normalizePath(path__default.relative(distDirectory, entrypoint.package.directory)))});

// this re-exports the source file
module.exports = require(${JSON.stringify(entrypointPath)});

unregister();
`;
}

function _lazyRequireBabelCore() {
  var mod = require("@babel/core");

  _lazyRequireBabelCore = function () {
    return mod;
  };

  return mod;
}

function getDevPath(cjsPath) {
  return cjsPath.replace(/\.js$/, ".dev.js");
}
function getProdPath(cjsPath) {
  return cjsPath.replace(/\.js$/, ".prod.js");
}
async function cleanProjectBeforeBuild(project) {
  await Promise.all(project.packages.map(async pkg => {
    await Promise.all([fs.remove(path__default.join(pkg.directory, "dist")), ...pkg.entrypoints.filter(entrypoint => entrypoint.name !== pkg.name).map(entrypoint => {
      return fs.remove(path__default.join(entrypoint.directory, "dist"));
    })]);
    const isTypeModule = pkg.isTypeModule();
    await Promise.all(pkg.entrypoints.map(async entrypoint => {
      if (isTsPath(entrypoint.source)) {
        if (!isTypeModule) {
          await fs.mkdir(path__default.join(entrypoint.directory, "dist"));
        }

        await writeDevTSFiles(entrypoint, (await entrypointHasDefaultExport(entrypoint, (await fs.readFile(entrypoint.source, "utf8")))));
      }
    }));
  }));
}

function nodeDevProdEntry() {
  return {
    name: "prod-dev-entry",

    async generateBundle(opts, bundle) {
      for (const n in bundle) {
        const file = bundle[n];

        if (file.type === "asset" || !(file.type === "chunk" && file.isEntry) || file.facadeModuleId == null) {
          continue;
        }

        let mainFieldPath = file.fileName.replace(/\.prod\.js$/, ".js");
        let mainEntrySource = `'use strict';

if (process.env.NODE_ENV === "production") {
  module.exports = require("./${path__default.basename(getProdPath(mainFieldPath))}");
} else {
  module.exports = require("./${path__default.basename(getDevPath(mainFieldPath))}");
}\n`;
        this.emitFile({
          type: "asset",
          fileName: mainFieldPath,
          source: mainEntrySource
        });
      }
    }

  };
}

function mjsProxyPlugin(pkg) {
  const entrypointSources = new Set(pkg.entrypoints.map(e => e.source));
  return {
    name: "mjs-proxy",

    async generateBundle(opts, bundle) {
      if (opts.format !== "cjs") return;

      for (const n in bundle) {
        const file = bundle[n];

        if (file.type === "asset" || !file.isEntry || file.facadeModuleId == null || !entrypointSources.has(normalizePath(file.facadeModuleId))) {
          continue;
        }

        let mjsPath = file.fileName.replace(/(?:\.prod)?\.js$/, ".mjs");
        const cjsRelativePath = `./${path__default.basename(mjsPath, ".mjs")}.js`;
        this.emitFile({
          type: "asset",
          fileName: mjsPath,
          source: mjsTemplate(file.exports, cjsRelativePath, mjsPath)
        });

        if (file.exports.includes("default")) {
          this.emitFile({
            type: "asset",
            fileName: getJsDefaultForMjsFilepath(mjsPath),
            source: jsDefaultForMjsTemplate(cjsRelativePath)
          });
        }
      }
    }

  };
}

let shouldUseWorker = process.env.DISABLE_PRECONSTRUCT_WORKER !== "true" && process.env.NODE_ENV !== "test" && !isCI;
let worker;
let unsafeRequire = require;
function createWorker() {
  if (shouldUseWorker) {
    worker = new Worker(require.resolve("@preconstruct/cli/worker"));
  } else {
    worker = unsafeRequire("@preconstruct/cli/worker");
  }
}
function destroyWorker() {
  if (worker !== undefined && shouldUseWorker) {
    worker.end();
    worker = undefined;
  }
}
function getWorker() {
  if (worker === undefined) {
    throw new Error("worker not defined");
  }

  return worker;
}

const lru = new QuickLRU({
  maxSize: 1000
});
let extensionRegex = /\.[tj]sx?$/;
let externalHelpersCache = new Map();

const resolvedBabelCore = require.resolve("@babel/core");

const babelHelpers = require(resolveFrom(resolvedBabelCore, "@babel/helpers"));

const babelGenerator = require(resolveFrom(resolvedBabelCore, "@babel/generator"));

const babelHelpersModuleStart = "\0rollupPluginBabelHelpers/"; // from https://github.com/babel/babel/blob/9808d2566e6a2b2d9e4c7890d8efbc9af180c683/packages/babel-core/src/transformation/file/file.js#L129-L164
// the main difference being that it uses a newer version of semver
// because the version of semver that @babel/core uses fails on semver.intersects calls with "*"

function babelRuntimeVersionRangeHasHelper(name, versionRange) {
  // babel's version has a try catch around this to handle unknown helpers
  // but if we're in here, we know that this version of @babel/helpers
  // understands the helper that we're getting the minVersion of
  let minVersion = babelHelpers.minVersion(name);
  return !semver.intersects(`<${minVersion}`, versionRange) && !semver.intersects(`>=8.0.0`, versionRange);
}

let rollupPluginBabel = ({
  cwd,
  reportTransformedFile,
  babelRuntime
}) => {
  // semver.intersects() has some surprising behavior with comparing ranges
  // with pre-release versions. We add '^' to ensure that we are always
  // comparing ranges with ranges, which sidesteps this logic.
  // For example:
  //
  //   semver.intersects(`<7.0.1`, "7.0.0-beta.0") // false - surprising
  //   semver.intersects(`<7.0.1`, "^7.0.0-beta.0") // true - expected
  //
  // This is because the first falls back to
  //
  //   semver.satisfies("7.0.0-beta.0", `<7.0.1`) // false - surprising
  //
  // and this fails because a prerelease version can only satisfy a range
  // if it is a prerelease within the same major/minor/patch range.
  //
  // Note: If this is found to have issues, please also revisit the logic in
  // transform-runtime's definitions.js file.
  const babelRuntimeVersion = semver.valid(babelRuntime === null || babelRuntime === void 0 ? void 0 : babelRuntime.range) ? `^${babelRuntime === null || babelRuntime === void 0 ? void 0 : babelRuntime.range}` : babelRuntime === null || babelRuntime === void 0 ? void 0 : babelRuntime.range;
  const resolveIdForBabelHelper = babelRuntimeVersion === undefined || babelRuntime === undefined || !semver.validRange(babelRuntimeVersion) ? helper => `${babelHelpersModuleStart}${helper}` : helper => {
    if (babelRuntimeVersionRangeHasHelper(helper, babelRuntimeVersion)) {
      return `${babelRuntime.name}/helpers/${helper}`;
    }

    return `${babelHelpersModuleStart}${helper}`;
  };
  return {
    name: "babel",

    resolveId(id, parent) {
      const currentIsBabelHelper = id.startsWith(babelHelpersModuleStart);

      if (!currentIsBabelHelper) {
        if (parent && parent.startsWith(babelHelpersModuleStart)) {
          return resolveIdForBabelHelper(id);
        }

        return null;
      }

      return resolveIdForBabelHelper(id.slice(babelHelpersModuleStart.length));
    },

    load(id) {
      let helperName = id.replace(/\0rollupPluginBabelHelpers\//, "");

      if (helperName === id) {
        return null;
      }

      let helpersSourceDescription = externalHelpersCache.get(helperName);

      if (helpersSourceDescription === undefined) {
        const helperNodes = babelHelpers.get(helperName).nodes;
        let helpers = babelGenerator.default( // @ts-ignore
        {
          type: "Program",
          body: helperNodes
        }).code;
        helpersSourceDescription = {
          ast: this.parse(helpers, undefined),
          code: helpers
        };
        externalHelpersCache.set(helperName, helpersSourceDescription);
      }

      return helpersSourceDescription;
    },

    transform(code, filename) {
      if (typeof filename !== "string" || filename[0] === "\0" || !extensionRegex.test(filename) || filename.includes("node_modules")) {
        return null;
      }

      if (lru.has(filename)) {
        let cachedResult = lru.get(filename);

        if (code === cachedResult.code) {
          return cachedResult.promise.then(result => {
            const ast = JSON.parse(JSON.stringify(result.ast));
            return {
              code: result.code,
              map: result.map,
              ast,
              meta: {
                babel: {
                  ast,
                  codeAtBabelTime: result.code
                }
              }
            };
          });
        }
      }

      let promise = getWorker().transformBabel(code, cwd, filename).then(x => {
        reportTransformedFile(filename);
        const ast = this.parse(x.code, undefined);
        return {
          code: x.code,
          ast: JSON.parse(JSON.stringify(ast, (_, value) => typeof value === "bigint" ? null : value)),
          map: x.map,
          meta: {
            babel: {
              ast,
              codeAtBabelTime: x.code
            }
          }
        };
      });
      lru.set(filename, {
        code,
        promise
      });
      return promise;
    }

  };
};

function terser(options) {
  return {
    name: "terser",

    renderChunk(code, chunk, outputOptions) {
      const normalizedOptions = _objectSpread(_objectSpread({}, options), {}, {
        module: outputOptions.format === "es"
      });

      const result = getWorker().transformTerser(code, JSON.stringify(normalizedOptions)).catch(error => {
        const {
          message,
          line,
          col: column
        } = error;
        console.error(codeFrameColumns(code, {
          start: {
            line,
            column
          }
        }, {
          message
        }));
        throw error;
      });
      return result;
    }

  };
}

function inlineProcessEnvNodeEnv({
  sourceMap
}) {
  return {
    name: "inline-process-env-node-env-production",

    transform(code, id) {
      if (code.includes("process.env.NODE_ENV")) {
        let magicString = new MagicString(code);

        const ast = (() => {
          const babelMeta = this.getModuleInfo(id).meta.babel;

          if ((babelMeta === null || babelMeta === void 0 ? void 0 : babelMeta.codeAtBabelTime) === code) {
            return this.getModuleInfo(id).meta.babel.ast;
          }

          return this.parse(code);
        })();

        walk(ast, {
          enter(n, p) {
            const parent = p;
            const node = n;

            if (node.type === "MemberExpression" && !node.computed && node.object.type === "MemberExpression" && !node.object.computed && node.object.object.type === "Identifier" && node.object.object.name === "process" && node.object.property.type === "Identifier" && node.object.property.name === "env" && node.property.type === "Identifier" && node.property.name === "NODE_ENV" && isReference(node, parent) && parent.type !== "AssignmentExpression") {
              const start = node.start;
              const end = node.end;
              const len = end - start;
              this.replace({
                type: "Literal",
                // @ts-ignore
                start,
                end,
                value: "production",
                raw: '"production"'
              });
              magicString.overwrite(start, end, '"production"'.padStart(len));
            }
          }

        });
        let output = {
          code: magicString.toString(),
          ast
        };

        if (sourceMap) {
          output.map = magicString.generateMap({
            hires: true
          });
        }

        return output;
      }

      return null;
    }

  };
}

const whitespace = /\s/;
function getModuleDirectives(source) {
  let lastDirectiveExpectingSemi;
  const directives = [];

  outer: for (let i = 0; i < source.length; i++) {
    const char = source[i];

    if (whitespace.test(char)) {
      continue;
    }

    if (char === "/") {
      i++;

      if (source[i] === "/") {
        while (i < source.length && source[i] !== "\r" && source[i] !== "\n") {
          i++;
        }

        continue;
      }

      if (source[i] === "*") {
        while (i < source.length && (source[i] !== "*" || source[i + 1] !== "/")) {
          i++;
        }

        i += 1;
        continue;
      }

      break;
    }

    if (char === ";") {
      if (lastDirectiveExpectingSemi !== undefined) {
        lastDirectiveExpectingSemi.end = i + 1;
        lastDirectiveExpectingSemi = undefined;
        continue;
      }

      break;
    }

    if (char === '"' || char === "'") {
      let start = i;
      i++;

      while (source[i] !== char) {
        if (i >= source.length) break outer;

        if (source[i] === "\\") {
          i += 2;
          continue;
        }

        i++;
      }

      const value = source.slice(start + 1, i);
      const directive = {
        value,
        start,
        end: i + 1
      };
      directives.push(directive);
      lastDirectiveExpectingSemi = directive;
      continue;
    }

    break;
  }

  return directives;
}

function serverComponentsPlugin({
  sourceMap
}) {
  return {
    name: "server-components",

    async resolveId(source, importer, opts) {
      var _loaded$meta$directiv;

      const resolved = await this.resolve(source, importer, _objectSpread(_objectSpread({}, opts), {}, {
        skipSelf: true
      }));

      if (resolved === null || resolved.external) {
        return resolved;
      }

      const loaded = await this.load(resolved);

      if (typeof ((_loaded$meta$directiv = loaded.meta.directivePreservedFile) === null || _loaded$meta$directiv === void 0 ? void 0 : _loaded$meta$directiv.referenceId) === "string" && importer !== undefined) {
        // this name is appended for Rollup naming chunks/variables in the output
        const name = path__default.basename(resolved.id).replace(/\.[tj]sx?$/, "").replace(/[^\w]/g, "_");
        const id = `__USE_CLIENT_IMPORT__${loaded.meta.directivePreservedFile.referenceId}__USE_CLIENT_IMPORT__/${name}`;
        return {
          id,
          external: true
        };
      }

      return resolved;
    },

    transform(code, id) {
      if (id.startsWith("\0")) return null;
      const directives = getModuleDirectives(code);
      const directive = directives.find(d => d.value === "use client" || d.value === "use server");
      if (!directive) return null;
      const magicString = new MagicString(code);
      const referenceId = this.emitFile({
        type: "chunk",
        id,
        preserveSignature: "allow-extension"
      });
      magicString.remove(directive.start, directive.end);
      return {
        code: magicString.toString(),
        map: sourceMap ? magicString.generateMap({
          hires: true
        }) : undefined,
        meta: {
          directivePreservedFile: {
            referenceId,
            directive: directive.value
          }
        }
      };
    },

    renderChunk(code, chunk) {
      const magicString = new MagicString(code);

      if (chunk.facadeModuleId !== null) {
        const moduleInfo = this.getModuleInfo(chunk.facadeModuleId);

        if (moduleInfo !== null && moduleInfo !== void 0 && moduleInfo.meta.directivePreservedFile) {
          const directive = moduleInfo === null || moduleInfo === void 0 ? void 0 : moduleInfo.meta.directivePreservedFile.directive;
          magicString.prepend(`'${directive}';\n`);
        }
      }

      magicString.replace(/__USE_CLIENT_IMPORT__(\w+?)__USE_CLIENT_IMPORT__\/\w+/g, (_, referenceId) => {
        const relative = normalizePath(path__default.relative(path__default.dirname(chunk.fileName), this.getFileName(referenceId)));
        return relative.startsWith("../") ? relative : `./${relative}`;
      });
      const stringified = magicString.toString();

      if (stringified === code) {
        return null;
      }

      return {
        code: magicString.toString(),
        map: sourceMap ? magicString.generateMap({
          hires: true
        }) : undefined
      };
    }

  };
}

const allowedExtensionRegex = /\.([tj]sx?|json)$/;
function resolveErrorsPlugin(pkg, warnings, isUmd) {
  return {
    name: "resolve-errors",

    async resolveId(source, importer) {
      var _resolved$id;

      let resolved = await this.resolve(source, importer, {
        skipSelf: true
      });

      if (resolved === null) {
        if (!source.startsWith(".")) {
          warnings.add(`"${source}" is imported ${importer ? `by "${normalizePath(path__default.relative(pkg.directory, importer))}"` : ""} but the package is not specified in dependencies or peerDependencies`);
          return false;
        }

        throw new FatalError(`Could not resolve ${source} ` + (importer ? `from ${path__default.relative(pkg.directory, importer)}` : ""), pkg.name);
      }

      if (source.startsWith("\0") || resolved.id.startsWith("\0")) {
        return resolved;
      }

      if (resolved.id.startsWith(pkg.directory)) {
        if (!resolved.external && !allowedExtensionRegex.test(resolved.id)) {
          warnings.add(`only .ts, .tsx, .js, .jsx, and .json files can be imported but "${source}" is imported in ${importer ? `"${normalizePath(path__default.relative(pkg.directory, importer))}"` : "a module"}`);
          return false;
        }

        return resolved;
      }

      if (isUmd || (_resolved$id = resolved.id) !== null && _resolved$id !== void 0 && _resolved$id.startsWith("__USE_CLIENT_IMPORT__")) {
        return resolved;
      }

      warnings.add(`all relative imports in a package should only import modules inside of their package directory but ${importer ? `"${normalizePath(path__default.relative(pkg.directory, importer))}"` : "a module"} is importing "${source}"`);
      return false;
    }

  };
}

function flow() {
  return {
    name: "flow",

    async generateBundle(opts, bundle) {
      for (const n in bundle) {
        const file = bundle[n];

        if (file.type === "asset" || !(file.type === "chunk" && file.isEntry) || file.facadeModuleId == null) {
          continue;
        }

        let mainFieldPath = file.fileName.replace(/(?:\.prod)?\.js$/, ".js");
        let relativeToSource = path__default.relative(path__default.dirname(path__default.join(opts.dir, file.fileName)), file.facadeModuleId);
        let isEntrySourceTypeScript = /\.tsx?$/.test(file.facadeModuleId);

        if (!isEntrySourceTypeScript) {
          let flowMode = false;
          let source = await fs.readFile(file.facadeModuleId, "utf8");

          if (source.includes("@flow")) {
            flowMode = file.exports.includes("default") ? "all" : "named";
          }

          if (flowMode !== false) {
            let flowFileSource = flowTemplate(flowMode === "all", normalizePath(relativeToSource));
            let flowFileName = mainFieldPath + ".flow";
            this.emitFile({
              type: "asset",
              fileName: flowFileName,
              source: flowFileSource
            });
          }
        }
      }
    }

  };
}

// this makes sure nested imports of external packages are external
const makeExternalPredicate = externalArr => {
  if (externalArr.length === 0) {
    return () => false;
  }

  const pattern = new RegExp(`^(${externalArr.join("|")})($|/)`);
  return id => pattern.test(id);
};

let getRollupConfig = (pkg, entrypoints, options, reportTransformedFile) => {
  var _pkg$exportsFieldConf;

  let external = [];

  if (pkg.json.peerDependencies) {
    external.push(...Object.keys(pkg.json.peerDependencies));
  }

  if (pkg.json.dependencies && options.kind !== "umd") {
    external.push(...Object.keys(pkg.json.dependencies));
  }

  external.push(pkg.name);

  let wrapExternalPredicate = inner => inner;

  if (options.kind === "node-dev" || options.kind === "node-prod" || options.kind === "conditions") {
    external.push(...builtInModules);

    wrapExternalPredicate = inner => source => source.startsWith("node:") || inner(source);
  }

  let input = {};
  const {
    distInRoot
  } = pkg.project.experimentalFlags;

  for (const entrypoint of entrypoints) {
    if (distInRoot) {
      input[`dist/${getBaseDistName(entrypoint)}`] = entrypoint.source;
      continue;
    }

    input[path__default.relative(pkg.directory, path__default.join(entrypoint.directory, "dist", getBaseDistName(entrypoint)))] = entrypoint.source;
  }

  let warnings = new Set();
  const isDefaultConditionsBuild = options.kind === "conditions" && options.conditions.length === 0;
  const config = {
    input,
    external: wrapExternalPredicate(makeExternalPredicate(external)),
    onwarn: warning => {
      if (typeof warning === "string") {
        warnings.add(`An unhandled Rollup error occurred: ${chalk.red( // @ts-ignore
        warning.toString())}`);
        return;
      }

      switch (warning.code) {
        case "CIRCULAR_DEPENDENCY":
        case "EMPTY_BUNDLE":
        case "EVAL":
        case "UNUSED_EXTERNAL_IMPORT":
          {
            break;
          }

        case "THIS_IS_UNDEFINED":
          {
            if (options.kind === "umd") {
              return;
            }

            warnings.add(`"${normalizePath(path__default.relative(pkg.directory, warning.loc.file))}" used \`this\` keyword at the top level of an ES module. You can read more about this at ${warning.url} and fix this issue that has happened here:\n\n${warning.frame}\n`);
            return;
          }

        default:
          {
            warnings.add(`An unhandled Rollup error occurred: ${chalk.red(warning.toString())}`);
          }
      }
    },
    plugins: [{
      name: "throw-warnings",

      buildEnd() {
        if (warnings.size) {
          throw new BatchError([...warnings].map(x => new FatalError(x, pkg.name)));
        }
      }

    }, options.kind === "node-prod" && nodeDevProdEntry(), (options.kind === "node-prod" || isDefaultConditionsBuild) && flow(), resolveErrorsPlugin(pkg, warnings, options.kind === "umd"), (options.kind === "node-prod" || isDefaultConditionsBuild) && typescriptDeclarations(pkg), (options.kind === "node-prod" || options.kind === "conditions") && ((_pkg$exportsFieldConf = pkg.exportsFieldConfig()) === null || _pkg$exportsFieldConf === void 0 ? void 0 : _pkg$exportsFieldConf.importConditionDefaultExport) === "default" && mjsProxyPlugin(pkg), serverComponentsPlugin({
      sourceMap: options.kind === "umd"
    }), rollupPluginBabel({
      cwd: pkg.project.directory,
      reportTransformedFile,
      babelRuntime: (() => {
        for (const dep of ["@babel/runtime", "@babel/runtime-corejs2", "@babel/runtime-corejs3"]) {
          var _pkg$json$dependencie;

          const range = (_pkg$json$dependencie = pkg.json.dependencies) === null || _pkg$json$dependencie === void 0 ? void 0 : _pkg$json$dependencie[dep];

          if (range !== undefined) {
            return {
              range,
              name: dep
            };
          }
        }
      })()
    }), options.kind === "umd" && cjs({
      include: ["**/node_modules/**", "node_modules/**"]
    }), rewriteBabelRuntimeHelpers(), json({
      namedExports: false
    }), options.kind === "umd" && alias({
      entries: getAliases(pkg.project)
    }), resolve({
      extensions: EXTENSIONS,
      exportConditions: options.kind === "conditions" ? options.conditions : undefined,
      // only umd builds will actually load dependencies which is where this browser flag actually makes a difference
      browser: options.kind === "umd",
      moduleDirectories: options.kind === "umd" ? ["node_modules"] : []
    }), options.kind === "umd" && inlineProcessEnvNodeEnv({
      sourceMap: true
    }), options.kind === "umd" && terser({
      sourceMap: true,
      compress: true
    }), options.kind === "node-prod" && inlineProcessEnvNodeEnv({
      sourceMap: false
    }), (options.kind === "browser" || options.kind === "umd") && replace({
      values: {
        ["typeof " + "document"]: JSON.stringify("object"),
        ["typeof " + "window"]: JSON.stringify("object")
      },
      preventAssignment: true
    }), options.kind === "worker" && replace({
      values: {
        ["typeof " + "document"]: JSON.stringify("undefined"),
        ["typeof " + "window"]: JSON.stringify("undefined")
      },
      preventAssignment: true
    }), pkg.project.experimentalFlags.keepDynamicImportAsDynamicImportInCommonJS && cjsDynamicImportPlugin].filter(x => !!x)
  };
  return config;
};

function getAliases(project) {
  let aliases = {};
  project.packages.forEach(pkg => {
    pkg.entrypoints.forEach(entrypoint => {
      aliases[entrypoint.name] = entrypoint.source;
    });
  });
  return aliases;
}

const cjsDynamicImportPlugin = {
  name: "cjs render dynamic import",

  renderDynamicImport({
    format
  }) {
    if (format !== "cjs") return;
    return {
      left: "import(",
      right: ")"
    };
  }

};

function getGlobal(project, name) {
  if (project.json.preconstruct.globals !== undefined && project.json.preconstruct.globals[name]) {
    return project.json.preconstruct.globals[name];
  } else {
    try {
      let pkgJson = require(resolveFrom(project.directory, path__default.join(name, "package.json")));

      if (pkgJson && pkgJson[PKG_JSON_CONFIG_FIELD] && pkgJson[PKG_JSON_CONFIG_FIELD].umdName) {
        return pkgJson[PKG_JSON_CONFIG_FIELD].umdName;
      }
    } catch (err) {
      if (err.code !== "MODULE_NOT_FOUND" && err.code !== "ERR_PACKAGE_PATH_NOT_EXPORTED") {
        throw err;
      }
    }

    throw limit(() => (async () => {
      // if while we were waiting, that global was added, return
      if (project.json.preconstruct.globals !== undefined && project.json.preconstruct.globals[name]) {
        return;
      }

      let response = await doPromptInput(`What should the umdName of ${name} be?`, project);

      if (!project.json.preconstruct.globals) {
        project.json.preconstruct.globals = {};
      }

      project.json.preconstruct.globals[name] = response;
      await project.save();
    })());
  }
}

const babelHelperId = /@babel\/runtime(|-corejs[23])\/helpers\//;

const interop = id => id && babelHelperId.test(id) ? "default" : "auto";

function getRollupConfigs(pkg) {
  let configs = umdBuilds(pkg);
  const exportsFieldConfig = pkg.exportsFieldConfig();

  if ((exportsFieldConfig === null || exportsFieldConfig === void 0 ? void 0 : exportsFieldConfig.conditions.kind) === "imports") {
    for (const conditions of exportsFieldConfig.conditions.groups.keys()) {
      const config = getRollupConfig(pkg, pkg.entrypoints, {
        kind: "conditions",
        conditions
      }, pkg.project.experimentalFlags.logCompiledFiles ? filename => {
        info("compiled " + filename.replace(pkg.project.directory + path__default.sep, ""));
      } : () => {});

      if (pkg.isTypeModule()) {
        configs.push({
          config,
          outputs: [{
            format: "es",
            entryFileNames: `[name].${getDistExtensionForConditionsWithTypeModule(conditions)}`,
            chunkFileNames: `dist/[name]-[hash].${getDistExtensionForConditionsWithTypeModule(conditions)}`,
            dir: pkg.directory
          }]
        });
        continue;
      }

      configs.push({
        config,
        outputs: [{
          format: "cjs",
          entryFileNames: `[name].${getDistExtensionForConditions(conditions)}`,
          chunkFileNames: `dist/[name]-[hash].${getDistExtensionForConditions(conditions)}`,
          dir: pkg.directory,
          exports: "named",
          interop
        }, {
          format: "es",
          entryFileNames: `[name].${getDistExtensionForConditions(conditions.concat("module"))}`,
          chunkFileNames: `dist/[name]-[hash].${getDistExtensionForConditions(conditions.concat("module"))}`,
          dir: pkg.directory
        }]
      });
    }

    return configs;
  }

  let hasModuleField = pkg.entrypoints[0].json.module !== undefined;
  configs.push({
    config: getRollupConfig(pkg, pkg.entrypoints, {
      kind: "node-dev"
    }, pkg.project.experimentalFlags.logCompiledFiles ? filename => {
      info("compiled " + filename.replace(pkg.project.directory + path__default.sep, ""));
    } : () => {}),
    outputs: [{
      format: "cjs",
      entryFileNames: "[name].cjs.dev.js",
      chunkFileNames: "dist/[name]-[hash].cjs.dev.js",
      dir: pkg.directory,
      exports: "named",
      interop
    }, ...(hasModuleField ? [{
      format: "es",
      entryFileNames: `[name].${getDistExtension("esm")}`,
      chunkFileNames: `dist/[name]-[hash].${getDistExtension("esm")}`,
      dir: pkg.directory
    }] : [])]
  });
  configs.push({
    config: getRollupConfig(pkg, pkg.entrypoints, {
      kind: "node-prod"
    }, () => {}),
    outputs: [{
      format: "cjs",
      entryFileNames: "[name].cjs.prod.js",
      chunkFileNames: "dist/[name]-[hash].cjs.prod.js",
      dir: pkg.directory,
      exports: "named",
      interop
    }]
  });
  let hasBrowserField = pkg.entrypoints[0].json.browser !== undefined;

  if (hasBrowserField) {
    configs.push({
      config: getRollupConfig(pkg, pkg.entrypoints, {
        kind: "browser"
      }, () => {}),
      outputs: [!exportsFieldConfig && {
        format: "cjs",
        entryFileNames: `[name].${getDistExtension("browser-cjs")}`,
        chunkFileNames: `dist/[name]-[hash].${getDistExtension("browser-cjs")}`,
        dir: pkg.directory,
        exports: "named",
        interop
      }, hasModuleField && {
        format: "es",
        entryFileNames: `[name].${getDistExtension("browser-esm")}`,
        chunkFileNames: `dist/[name]-[hash].${getDistExtension("browser-esm")}`,
        dir: pkg.directory
      }].filter(value => value !== false)
    });
  } // note module builds always exist when using the exports field


  if ((exportsFieldConfig === null || exportsFieldConfig === void 0 ? void 0 : exportsFieldConfig.conditions.kind) === "legacy" && exportsFieldConfig !== null && exportsFieldConfig !== void 0 && exportsFieldConfig.conditions.envs.has("worker")) {
    configs.push({
      config: getRollupConfig(pkg, pkg.entrypoints, {
        kind: "worker"
      }, () => {}),
      outputs: [{
        format: "es",
        entryFileNames: `[name].${getDistExtension("worker")}`,
        chunkFileNames: `dist/[name]-[hash].${getDistExtension("worker")}`,
        dir: pkg.directory
      }]
    });
  }

  return configs;
}

function umdBuilds(pkg) {
  // umd builds are a bit special
  // we don't guarantee that shared modules are shared across umd builds
  // this is just like dependencies, they're bundled into the umd build
  if (pkg.entrypoints[0].json["umd:main"] !== undefined) return pkg.entrypoints.map(entrypoint => {
    return {
      config: getRollupConfig(pkg, [entrypoint], {
        kind: "umd"
      }, () => {}),
      outputs: [{
        format: "umd",
        sourcemap: true,
        entryFileNames: `[name].${getDistExtension("umd")}`,
        name: entrypoint.json.preconstruct.umdName,
        dir: pkg.directory,
        interop,
        globals: name => {
          if (name === entrypoint.json.preconstruct.umdName) {
            return name;
          }

          return getGlobal(pkg.project, name);
        }
      }]
    };
  });
  return [];
}

// this looks ridiculous, but it prevents sourcemap tooling from mistaking
// this for an actual sourceMappingURL

let SOURCEMAPPING_URL = "sourceMa";
SOURCEMAPPING_URL += "ppingURL"; // https://github.com/rollup/rollup/blob/28ffcf4c4a2ab4323091f63944b2a609b7bcd701/src/rollup/rollup.ts#L333-L356

function writeOutputFile(outputFile, outputOptions) {
  const fileName = path__default.resolve(outputOptions.dir || path__default.dirname(outputOptions.file), outputFile.fileName);
  let writeSourceMapPromise;
  let source;

  if (outputFile.type === "asset") {
    source = outputFile.source;
  } else {
    source = outputFile.code;

    if (outputOptions.sourcemap && outputFile.map) {
      let url;

      if (outputOptions.sourcemap === "inline") {
        url = outputFile.map.toUrl();
      } else {
        url = `${path__default.basename(outputFile.fileName)}.map`;
        writeSourceMapPromise = fs.outputFile(`${fileName}.map`, outputFile.map.toString());
      }

      if (outputOptions.sourcemap !== "hidden") {
        source += `//# ${SOURCEMAPPING_URL}=${url}\n`;
      }
    }
  }

  return Promise.all([fs.outputFile(fileName, source), writeSourceMapPromise]);
}

async function buildPackage(pkg) {
  let configs = getRollupConfigs(pkg);
  let outputs = await Promise.all(configs.map(async ({
    config,
    outputs
  }) => {
    let bundle = await rollup(config);
    return Promise.all(outputs.map(async outputConfig => {
      return {
        output: (await bundle.generate(outputConfig)).output,
        outputConfig
      };
    }));
  }));
  await Promise.all(outputs.map(x => {
    return Promise.all(x.map(bundle => {
      return Promise.all(bundle.output.map(output => {
        return writeOutputFile(output, bundle.outputConfig);
      }));
    }));
  }));
}

async function retryableBuild(pkg) {
  try {
    await buildPackage(pkg);
  } catch (err) {
    if (err instanceof Promise) {
      await err;
      await retryableBuild(pkg);
      return;
    }

    if (err instanceof FatalError || err instanceof BatchError || err instanceof ScopelessError) {
      throw err;
    }

    if (err.pluginCode === "BABEL_PARSE_ERROR") {
      throw new ScopelessError(err.message);
    }

    throw new UnexpectedBuildError(err, pkg.name);
  }
}

async function build$1(directory) {
  // do more stuff with checking whether the repo is using yarn workspaces or bolt
  try {
    createWorker();
    let project = await Project.create(directory);
    validateProject(project);
    info("building bundles!");
    await cleanProjectBeforeBuild(project);
    let errors = [];
    await Promise.all(project.packages.map(async pkg => {
      try {
        await retryableBuild(pkg);
      } catch (err) {
        if (err instanceof BatchError) {
          errors.push(...err.errors);
        } else {
          errors.push(err);
        }
      }
    }));

    if (errors.length) {
      throw new BatchError(errors.sort((a, b) => (a.scope + a.message).localeCompare(b.scope + b.message)));
    }

    success("built bundles!");
  } finally {
    destroyWorker();
  }
}

function relativePath(id) {
  return path__default.relative(process.cwd(), id);
}

async function watchPackage(pkg) {
  const _configs = getRollupConfigs(pkg);

  let configs = _configs.map(config => {
    return _objectSpread(_objectSpread({}, config.config), {}, {
      output: config.outputs
    });
  });

  const watcher = watch(configs);
  let reject;
  let errPromise = new Promise((resolve, _reject) => {
    reject = _reject;
  });
  let startResolve;
  let startPromise = new Promise(resolve => {
    startResolve = resolve;
  });
  watcher.on("event", event => {
    // https://github.com/rollup/rollup/blob/aed954e4e6e8beabd47268916ff0955fbb20682d/bin/src/run/watch.ts#L71-L115
    switch (event.code) {
      case "ERROR":
        {
          reject(event.error);
          break;
        }

      case "START":
        startResolve();
        break;

      case "BUNDLE_START":
        {
          info(chalk.cyan(`bundles ${chalk.bold(typeof event.input === "string" ? relativePath(event.input) : Array.isArray(event.input) ? event.input.map(relativePath).join(", ") : event.input === undefined ? "" : Object.values(event.input) // @ts-ignore
          .map(relativePath).join(", "))} â†’ ${chalk.bold(event.output.map(relativePath).join(", "))}...`), pkg.name);
          break;
        }

      case "BUNDLE_END":
        {
          info(chalk.green(`created ${chalk.bold(event.output.map(relativePath).join(", "))} in ${chalk.bold(ms(event.duration))}`), pkg.name);
          break;
        }

      case "END":
        {
          info("waiting for changes...", pkg.name);
        }
    }
  });
  return {
    error: errPromise,
    start: startPromise
  };
}

async function retryableWatch(pkg, getPromises, depth) {
  try {
    let {
      error,
      start
    } = await watchPackage(pkg);

    if (depth === 0) {
      getPromises({
        start
      });
    }

    await error;
  } catch (err) {
    if (err instanceof Promise) {
      await err;
      await retryableWatch(pkg, getPromises, depth + 1);
      return;
    }

    throw err;
  }
}

async function build(directory) {
  createWorker();
  let project = await Project.create(directory);
  validateProject(project);
  await cleanProjectBeforeBuild(project);
  let startCount = 0;
  await Promise.all(project.packages.map(pkg => retryableWatch(pkg, async ({
    start
  }) => {
    await start;
    startCount++;

    if (startCount === project.packages.length) {
      success(successes.startedWatching);
    }
  }, 0)));
}

let keys = Object.keys;

async function fixPackage(pkg) {
  if (pkg.entrypoints.length === 0) {
    throw new FatalError(errors$1.noEntrypoints, pkg.name);
  }

  const exportsFieldConfig = pkg.exportsFieldConfig();
  let fields = {
    main: true,
    module: pkg.entrypoints.some(x => x.json.module !== undefined) || !!exportsFieldConfig,
    "umd:main": pkg.entrypoints.some(x => x.json["umd:main"] !== undefined),
    browser: pkg.entrypoints.some(x => x.json.browser !== undefined)
  };

  if ((exportsFieldConfig === null || exportsFieldConfig === void 0 ? void 0 : exportsFieldConfig.conditions.kind) === "legacy") {
    if (fields.browser || exportsFieldConfig.conditions.envs.has("browser")) {
      if (typeof pkg.json.preconstruct.exports !== "object") {
        pkg.json.preconstruct.exports = {};
      }

      if (!pkg.json.preconstruct.exports.envConditions) {
        pkg.json.preconstruct.exports.envConditions = [];
      }

      if (!pkg.json.preconstruct.exports.envConditions.includes("browser")) {
        pkg.json.preconstruct.exports.envConditions.push("browser");
      }

      fields.browser = true;
    }
  }

  if (!pkg.isTypeModule()) {
    keys(fields).filter(x => fields[x]).forEach(field => {
      pkg.setFieldOnEntrypoints(field);
    });
  }

  pkg.json = setFieldInOrder(pkg.json, "exports", exportsField(pkg));

  for (const entrypoint of pkg.entrypoints) {
    if (entrypoint.json["umd:main"] !== undefined && !isUmdNameSpecified(entrypoint)) {
      let umdName = await promptInput(inputs.getUmdName, entrypoint);
      entrypoint.json.preconstruct.umdName = umdName;
    }
  }

  return async () => (await Promise.all([pkg.save(), ...(pkg.isTypeModule() ? [] : pkg.entrypoints.map(x => x.directory !== pkg.directory ? x.save() : false))])).some(x => x);
}

async function fix(directory) {
  let project = await Project.create(directory, true);
  let didModifyProject = false;

  if (project.json.preconstruct.___experimentalFlags_WILL_CHANGE_IN_PATCH) {
    let errors = [];
    Object.keys(project.json.preconstruct.___experimentalFlags_WILL_CHANGE_IN_PATCH).forEach(key => {
      if (FORMER_FLAGS_THAT_ARE_ENABLED_NOW.has(key)) {
        didModifyProject = true;
        delete project.json.preconstruct.___experimentalFlags_WILL_CHANGE_IN_PATCH[key];
      } else if (!EXPERIMENTAL_FLAGS.has(key)) {
        errors.push(new FatalError(`The experimental flag ${JSON.stringify(key)} in your config does not exist`, project.name));
      }
    });

    if (didModifyProject) {
      if (Object.keys(project.json.preconstruct.___experimentalFlags_WILL_CHANGE_IN_PATCH).length === 0) {
        delete project.json.preconstruct.___experimentalFlags_WILL_CHANGE_IN_PATCH;
      }

      await project.save();
    }

    if (errors.length) {
      throw new BatchError(errors);
    }
  }

  const updaters = await Promise.all(project.packages.map(fixPackage));
  const didModifyPackages = (await Promise.all(updaters.map(x => x()))).some(x => x);
  success(didModifyProject || didModifyPackages ? "fixed project!" : "project already valid!");
}

process.env.NODE_ENV = "production";
let {
  input
} = meow(`
Usage
  $ preconstruct [command]
Commands
  init         initialise a project
  build        build the project
  watch        start a watch process to build the project
  validate     validate the project
  fix          infer as much information as possible and fix the project
  dev          create links so entrypoints can be imported

`, {});
let errors = {
  commandNotFound: "Command not found"
};

class CommandNotFoundError extends Error {}

(async () => {
  if (input.length === 1) {
    switch (input[0]) {
      case "init":
        {
          await init(process.cwd());
          return;
        }

      case "validate":
        {
          await validate(process.cwd());
          return;
        }

      case "build":
        {
          await build$1(process.cwd());
          return;
        }

      case "watch":
        {
          await build(process.cwd());
          return;
        }

      case "fix":
        {
          await fix(process.cwd());
          return;
        }

      case "dev":
        {
          await dev(process.cwd());
          return;
        }

      default:
        {
          throw new CommandNotFoundError();
        }
    }
  } else {
    throw new CommandNotFoundError();
  }
})().catch(err => {
  let hasFixableError = false;

  if (err instanceof FixableError) {
    hasFixableError = true;
    error(err.message, err.scope);
  } else if (err instanceof FatalError) {
    error(err.message, err.scope);
  } else if (err instanceof BatchError) {
    for (let fatalError of err.errors) {
      if (fatalError instanceof FixableError) {
        hasFixableError = true;
        error(fatalError.message, fatalError.scope);
      } else {
        error(fatalError.message, fatalError.scope);
      }
    }
  } else if (err instanceof CommandNotFoundError) {
    error(errors.commandNotFound);
  } else if (err instanceof UnexpectedBuildError) {
    error(err.message, err.scope);
  } else if (err instanceof ScopelessError) {
    log(err.message);
  } else {
    error(err);
  }

  if (hasFixableError) {
    info("Some of the errors above can be fixed automatically by running preconstruct fix");
  }

  info("If you want to learn more about the above error, check https://preconstruct.tools/errors");
  info("If the error is not there and you want to learn more about it, open an issue at https://github.com/preconstruct/preconstruct/issues/new");
  process.exit(1);
});
